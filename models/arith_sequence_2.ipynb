{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TOkFQfQEagAu",
        "outputId": "98165afd-da41-44b2-813c-26f83675784f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: jaxtyping in /usr/local/lib/python3.10/dist-packages (0.2.33)\n",
            "Requirement already satisfied: typeguard==2.13.3 in /usr/local/lib/python3.10/dist-packages (from jaxtyping) (2.13.3)\n",
            "Collecting git+https://github.com/samarth-bhargav/TransformerLens.git\n",
            "  Cloning https://github.com/samarth-bhargav/TransformerLens.git to /tmp/pip-req-build-4mp0ur34\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/samarth-bhargav/TransformerLens.git /tmp/pip-req-build-4mp0ur34\n",
            "  Resolved https://github.com/samarth-bhargav/TransformerLens.git to commit c43b244d815ae69c468a3acbcb9e52b6a2db8f6d\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (0.32.1)\n",
            "Collecting beartype<0.15.0,>=0.14.1 (from transformer-lens==0.0.0)\n",
            "  Using cached beartype-0.14.1-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting better-abc<0.0.4,>=0.0.3 (from transformer-lens==0.0.0)\n",
            "  Using cached better_abc-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting datasets>=2.7.1 (from transformer-lens==0.0.0)\n",
            "  Using cached datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (0.8.0)\n",
            "Collecting fancy-einsum>=0.0.3 (from transformer-lens==0.0.0)\n",
            "  Using cached fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: jaxtyping>=0.2.11 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (0.2.33)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.1.4)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (13.7.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (0.1.99)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.66.5)\n",
            "Requirement already satisfied: transformers>=4.37.2 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.42.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.12.2)\n",
            "Collecting wandb>=0.13.5 (from transformer-lens==0.0.0)\n",
            "  Using cached wandb-0.17.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (0.23.5)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens==0.0.0) (0.4.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.15.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Using cached pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Using cached xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.7.1->transformer-lens==0.0.0) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.10.2)\n",
            "Requirement already satisfied: typeguard==2.13.3 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.11->transformer-lens==0.0.0) (2.13.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2024.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10->transformer-lens==0.0.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10->transformer-lens==0.0.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10->transformer-lens==0.0.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10->transformer-lens==0.0.0)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10->transformer-lens==0.0.0)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10->transformer-lens==0.0.0)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10->transformer-lens==0.0.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10->transformer-lens==0.0.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10->transformer-lens==0.0.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10->transformer-lens==0.0.0)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10->transformer-lens==0.0.0)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10->transformer-lens==0.0.0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer-lens==0.0.0) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer-lens==0.0.0) (0.19.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.20.3)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Using cached sentry_sdk-2.13.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting setproctitle (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Using cached setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer-lens==0.0.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer-lens==0.0.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer-lens==0.0.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer-lens==0.0.0) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer-lens==0.0.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer-lens==0.0.0) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Using cached beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "Using cached better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
            "Using cached datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "Using cached fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading wandb-0.17.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.13.0-py2.py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.1/309.1 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: transformer-lens\n",
            "  Building wheel for transformer-lens (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformer-lens: filename=transformer_lens-0.0.0-py3-none-any.whl size=174207 sha256=d90c7cfce03d35a3ac7d51730863b1869ec13bf5b07abce0a3a1353a00caec46\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3kitzx1m/wheels/72/b6/8a/dd6c3f40d9fa64c3eb69131115102957c3f6f30e745b68d3de\n",
            "Successfully built transformer-lens\n",
            "Installing collected packages: better-abc, xxhash, smmap, setproctitle, sentry-sdk, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fancy-einsum, docker-pycreds, dill, beartype, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, gitdb, nvidia-cusolver-cu12, gitpython, wandb, datasets, transformer-lens\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed beartype-0.14.1 better-abc-0.0.3 datasets-2.21.0 dill-0.3.8 docker-pycreds-0.4.0 fancy-einsum-0.0.3 gitdb-4.0.11 gitpython-3.1.43 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 pyarrow-17.0.0 sentry-sdk-2.13.0 setproctitle-1.3.3 smmap-5.0.1 transformer-lens-0.0.0 wandb-0.17.7 xxhash-3.4.1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "THPDtypeType.tp_dict == nullptr INTERNAL ASSERT FAILED at \"../torch/csrc/Dtype.cpp\":176, please report a bug to PyTorch. ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d7eac5f571a8>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# from transformer_lens import HookedTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# from transformer_lens.utils import gelu_new, tokenize_and_concatenate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: THPDtypeType.tp_dict == nullptr INTERNAL ASSERT FAILED at \"../torch/csrc/Dtype.cpp\":176, please report a bug to PyTorch. "
          ]
        }
      ],
      "source": [
        "%pip install einops\n",
        "%pip install jaxtyping\n",
        "%pip install git+https://github.com/samarth-bhargav/TransformerLens.git\n",
        "\n",
        "import einops\n",
        "from dataclasses import dataclass\n",
        "# from transformer_lens import HookedTransformer\n",
        "# from transformer_lens.utils import gelu_new, tokenize_and_concatenate\n",
        "import torch as t\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from jaxtyping import Float, Int\n",
        "from pathlib import Path\n",
        "from typing import Tuple, List, Optional, Dict, Callable\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import transformer_lens\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
        "from transformer_lens.utils import gelu_new, tokenize_and_concatenate\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content\")\n",
        "import plot\n",
        "\n",
        "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C8oa2C1TagAv"
      },
      "outputs": [],
      "source": [
        "cfg = HookedTransformerConfig(\n",
        "    d_model = 128,\n",
        "    n_layers = 2,\n",
        "    n_heads = 12,\n",
        "    d_head = 64,\n",
        "    d_mlp = 3072,\n",
        "    n_ctx = 32,\n",
        "    d_vocab = 40,\n",
        "    act_fn = 'gelu_new'\n",
        ")\n",
        "\n",
        "cfg.init_range = 0.02\n",
        "cfg.layer_norm_eps = 1e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e9JJ_vBcagAw"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, cfg: HookedTransformerConfig):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.w = nn.Parameter(t.ones(cfg.d_model))\n",
        "        self.b = nn.Parameter(t.zeros(cfg.d_model))\n",
        "\n",
        "    def forward(self, residual: Float[Tensor, \"batch posn d_model\"]) -> Float[Tensor, \"batch posn d_model\"]:\n",
        "        # SOLUTION\n",
        "        residual_mean = residual.mean(dim=-1, keepdim=True)\n",
        "        residual_std = (residual.var(dim=-1, keepdim=True, unbiased=False) + self.cfg.layer_norm_eps).sqrt()\n",
        "\n",
        "        residual = (residual - residual_mean) / residual_std\n",
        "        return residual * self.w + self.b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bIQTnFhoagAw"
      },
      "outputs": [],
      "source": [
        "class Embed(nn.Module):\n",
        "    def __init__(self, cfg: HookedTransformerConfig):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_E = nn.Parameter(t.empty(cfg.d_vocab, cfg.d_model))\n",
        "        nn.init.normal_(self.W_E, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(self, vecs: Float[Tensor, \"batch position d_vocab\"]) -> Float[Tensor, \"batch position d_model\"]:\n",
        "        # SOLUTION\n",
        "        return einops.einsum(vecs, self.W_E, \"batch position d_vocab, d_vocab d_model -> batch position d_model\")\n",
        "\n",
        "transformer_lens.components.embed.Embed = Embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CrVeDRdmagAw"
      },
      "outputs": [],
      "source": [
        "class PosEmbed(nn.Module):\n",
        "    def __init__(self, cfg: HookedTransformerConfig):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_pos = nn.Parameter(t.empty((cfg.n_ctx, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_pos, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(self, vecs: Float[Tensor, \"batch position d_vocab\"]) -> Float[Tensor, \"batch position d_model\"]:\n",
        "        # SOLUTION\n",
        "        batch, seq_len, _ = vecs.shape\n",
        "        return einops.repeat(self.W_pos[:seq_len], \"seq d_model -> batch seq d_model\", batch=batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eIguR7h4agAw"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    IGNORE: Float[Tensor, \"\"]\n",
        "\n",
        "    def __init__(self, cfg: HookedTransformerConfig):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_Q = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        self.W_K = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        self.W_V = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        self.W_O = nn.Parameter(t.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n",
        "        self.b_Q = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.b_K = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.b_V = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.b_O = nn.Parameter(t.zeros((cfg.d_model)))\n",
        "        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n",
        "        self.register_buffer(\"IGNORE\", t.tensor(float(\"-inf\"), dtype=t.float32, device=device))\n",
        "\n",
        "    def forward(\n",
        "        self, normalized_resid_pre: Float[Tensor, \"batch posn d_model\"]\n",
        "    ) -> Float[Tensor, \"batch posn d_model\"]:\n",
        "        # SOLUTION\n",
        "        # Calculate query, key and value vectors\n",
        "        q = einops.einsum(\n",
        "            normalized_resid_pre, self.W_Q,\n",
        "            \"batch posn d_model, nheads d_model d_head -> batch posn nheads d_head\",\n",
        "        ) + self.b_Q\n",
        "        k = einops.einsum(\n",
        "            normalized_resid_pre, self.W_K,\n",
        "            \"batch posn d_model, nheads d_model d_head -> batch posn nheads d_head\",\n",
        "        ) + self.b_K\n",
        "        v = einops.einsum(\n",
        "            normalized_resid_pre, self.W_V,\n",
        "            \"batch posn d_model, nheads d_model d_head -> batch posn nheads d_head\",\n",
        "        ) + self.b_V\n",
        "\n",
        "        # Calculate attention scores, then scale and mask, and apply softmax to get probabilities\n",
        "        attn_scores = einops.einsum(\n",
        "            q, k,\n",
        "            \"batch posn_Q nheads d_head, batch posn_K nheads d_head -> batch nheads posn_Q posn_K\",\n",
        "        )\n",
        "        attn_scores_masked = self.apply_causal_mask(attn_scores / self.cfg.d_head ** 0.5)\n",
        "        attn_pattern = attn_scores_masked.softmax(-1)\n",
        "\n",
        "        # Take weighted sum of value vectors, according to attention probabilities\n",
        "        z = einops.einsum(\n",
        "            v, attn_pattern,\n",
        "            \"batch posn_K nheads d_head, batch nheads posn_Q posn_K -> batch posn_Q nheads d_head\",\n",
        "        )\n",
        "\n",
        "        # Calculate output (by applying matrix W_O and summing over heads, then adding bias b_O)\n",
        "        attn_out = einops.einsum(\n",
        "            z, self.W_O,\n",
        "            \"batch posn_Q nheads d_head, nheads d_head d_model -> batch posn_Q d_model\",\n",
        "        ) + self.b_O\n",
        "\n",
        "        return attn_out\n",
        "\n",
        "    def apply_causal_mask(\n",
        "        self, attn_scores: Float[Tensor, \"batch n_heads query_pos key_pos\"]\n",
        "    ) -> Float[Tensor, \"batch n_heads query_pos key_pos\"]:\n",
        "        '''\n",
        "        Applies a causal mask to attention scores, and returns masked scores.\n",
        "        '''\n",
        "        # SOLUTION\n",
        "        # Define a mask that is True for all positions we want to set probabilities to zero for\n",
        "        all_ones = t.ones(attn_scores.size(-2), attn_scores.size(-1), device=attn_scores.device)\n",
        "        mask = t.triu(all_ones, diagonal=1).bool()\n",
        "        # Apply the mask to attention scores, then return the masked scores\n",
        "        attn_scores.masked_fill_(mask, self.IGNORE)\n",
        "        return attn_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "A67hIUfnagAw"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, cfg: HookedTransformerConfig):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_in = nn.Parameter(t.empty((cfg.d_model, cfg.d_mlp)))\n",
        "        self.W_out = nn.Parameter(t.empty((cfg.d_mlp, cfg.d_model)))\n",
        "        self.b_in = nn.Parameter(t.zeros((cfg.d_mlp)))\n",
        "        self.b_out = nn.Parameter(t.zeros((cfg.d_model)))\n",
        "        nn.init.normal_(self.W_in, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_out, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(\n",
        "        self, normalized_resid_mid: Float[Tensor, \"batch posn d_model\"]\n",
        "    ) -> Float[Tensor, \"batch posn d_model\"]:\n",
        "        # SOLUTION\n",
        "        pre = einops.einsum(\n",
        "            normalized_resid_mid, self.W_in,\n",
        "            \"batch position d_model, d_model d_mlp -> batch position d_mlp\",\n",
        "        ) + self.b_in\n",
        "        post = gelu_new(pre)\n",
        "        mlp_out = einops.einsum(\n",
        "            post, self.W_out,\n",
        "            \"batch position d_mlp, d_mlp d_model -> batch position d_model\",\n",
        "        ) + self.b_out\n",
        "        return mlp_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IIlCY7HOagAx"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg: HookedTransformerConfig):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.ln1 = LayerNorm(cfg)\n",
        "        self.attn = Attention(cfg)\n",
        "        self.ln2 = LayerNorm(cfg)\n",
        "        self.mlp = MLP(cfg)\n",
        "\n",
        "    def forward(\n",
        "        self, resid_pre: Float[Tensor, \"batch position d_model\"]\n",
        "    ) -> Float[Tensor, \"batch position d_model\"]:\n",
        "        # SOLUTION\n",
        "        resid_mid = self.attn(self.ln1(resid_pre)) + resid_pre\n",
        "        resid_post = self.mlp(self.ln2(resid_mid)) + resid_mid\n",
        "        return resid_post"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fBGXQE0cagAx"
      },
      "outputs": [],
      "source": [
        "class Unembed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_U = nn.Parameter(t.empty((cfg.d_model, cfg.d_vocab)))\n",
        "        nn.init.normal_(self.W_U, std=self.cfg.init_range)\n",
        "        self.b_U = nn.Parameter(t.zeros((cfg.d_vocab), requires_grad=False))\n",
        "\n",
        "    def forward(\n",
        "        self, normalized_resid_final: Float[Tensor, \"batch position d_model\"]\n",
        "    ) -> Float[Tensor, \"batch position d_vocab\"]:\n",
        "        # SOLUTION\n",
        "        return einops.einsum(\n",
        "            normalized_resid_final, self.W_U,\n",
        "            \"batch posn d_model, d_model d_vocab -> batch posn d_vocab\",\n",
        "        ) + self.b_U\n",
        "        # Or, could just do `normalized_resid_final @ self.W_U + self.b_U`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "POhmOvvPagAx"
      },
      "outputs": [],
      "source": [
        "class DemoTransformer(nn.Module):\n",
        "    def __init__(self, cfg: HookedTransformerConfig):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.embed = Embed(cfg)\n",
        "        self.pos_embed = PosEmbed(cfg)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n",
        "        self.ln_final = LayerNorm(cfg)\n",
        "        self.unembed = Unembed(cfg)\n",
        "\n",
        "    def forward(self, tokens: Float[Tensor, \"batch position d_vocab\"]) -> Float[Tensor, \"batch position d_vocab\"]:\n",
        "        # SOLUTION\n",
        "        residual = self.embed(tokens) + self.pos_embed(tokens)\n",
        "        for block in self.blocks:\n",
        "            residual = block(residual)\n",
        "        prediction = self.unembed(self.ln_final(residual))\n",
        "        return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3s_3sy3MagAx"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class TransformerTrainingArgs():\n",
        "\tbatch_size = 16\n",
        "\tlr = 1e-4\n",
        "\tweight_decay = 1e-2\n",
        "\twandb_project: Optional[str] = \"day1-demotransformer\"\n",
        "\twandb_name: Optional[str] = None\n",
        "\n",
        "\n",
        "args = TransformerTrainingArgs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpeSo_cFagAx",
        "outputId": "c8af6157-a860-43c3-c161-325522e98cf2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-1.3898e-02, -8.4231e-04, -9.0464e-03,  ..., -2.1358e-03,\n",
              "           -1.0883e-02, -1.4151e-02],\n",
              "          [ 2.5793e-04, -4.3577e-03, -1.1750e-02,  ...,  3.9989e-03,\n",
              "           -2.2661e-02, -7.6783e-03],\n",
              "          [ 1.4413e-02, -7.8730e-03, -1.4453e-02,  ...,  1.0134e-02,\n",
              "           -3.4439e-02, -1.2055e-03],\n",
              "          ...,\n",
              "          [ 3.6830e-01, -9.5757e-02, -8.2036e-02,  ...,  1.6350e-01,\n",
              "           -3.2889e-01,  1.6061e-01],\n",
              "          [ 3.8246e-01, -9.9272e-02, -8.4740e-02,  ...,  1.6963e-01,\n",
              "           -3.4067e-01,  1.6709e-01],\n",
              "          [ 3.9661e-01, -1.0279e-01, -8.7443e-02,  ...,  1.7577e-01,\n",
              "           -3.5244e-01,  1.7356e-01]]]),\n",
              " (tensor([[1.]]),\n",
              "  tensor([[[ 0.0142, -0.0035, -0.0027,  0.0039,  0.0131,  0.0121,  0.0053,\n",
              "            -0.0135,  0.0112, -0.0007, -0.0072,  0.0139, -0.0005,  0.0107,\n",
              "             0.0046, -0.0039, -0.0056, -0.0103, -0.0106, -0.0035,  0.0124,\n",
              "            -0.0104,  0.0127, -0.0007,  0.0047, -0.0063,  0.0071, -0.0036,\n",
              "             0.0038,  0.0101,  0.0124,  0.0083, -0.0101,  0.0043,  0.0010,\n",
              "             0.0027,  0.0059,  0.0061, -0.0118,  0.0065]]])))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "def rand_range(low, high, shape):\n",
        "  return t.rand(shape) * (high - low) + low\n",
        "\n",
        "def generate_linear_recurrences(batch_size, vector_dim=40, compl=1, length=30, param_bds = (-3, 3), return_type=\"both\"):\n",
        "\n",
        "    assert compl < length\n",
        "    assert param_bds[0] <= param_bds[1]\n",
        "\n",
        "    params = rand_range(1, 1, (batch_size, compl)).to(device)\n",
        "    consts = rand_range(param_bds[0], param_bds[1], (batch_size, vector_dim)).to(device)\n",
        "\n",
        "    recurrences = t.empty((batch_size, length, vector_dim)).to(device)\n",
        "\n",
        "    recurrences[:, :compl] = rand_range(-3, 3, (batch_size, 1, vector_dim))\n",
        "\n",
        "    for j in range(compl, length):\n",
        "        recurrences[:, j] = consts + einops.einsum(params, recurrences[:, j-compl:j], \"batch compl, batch compl vector_dim -> batch vector_dim\")\n",
        "\n",
        "    #find max norm in each batch and divide each batch by that max norm\n",
        "    max_norms, _ = t.max(t.norm(recurrences, dim=2, keepdim=True), dim=1, keepdim=True)\n",
        "    caps = (t.rand((batch_size, 1, 1)) * (2 - 1) + 1).to(device)\n",
        "    recurrences = recurrences / (max_norms / caps)\n",
        "\n",
        "    max_norms = max_norms.squeeze(1)\n",
        "\n",
        "    if return_type == 'seq':\n",
        "        return recurrences\n",
        "    elif return_type == 'both':\n",
        "        return recurrences, (params, consts / (max_norms / caps))\n",
        "\n",
        "    assert False\n",
        "\n",
        "generate_linear_recurrences(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kSOSWi6aagAy"
      },
      "outputs": [],
      "source": [
        "class TransformerTrainer:\n",
        "    def __init__(self, args: TransformerTrainingArgs, model: DemoTransformer):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.args = args\n",
        "        self.optimizer = t.optim.AdamW(self.model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "        self.loss = nn.MSELoss()\n",
        "        self.step = 0\n",
        "\n",
        "\n",
        "    def training_step(self, batch: Float[Tensor, \"batch seq d_vocab\"]) -> Float[Tensor, \"\"]:\n",
        "        '''\n",
        "        Calculates the loss on the tokens in the batch, performs a gradient update step, and logs the loss.\n",
        "\n",
        "        Remember that `batch` is a dictionary with the single key 'tokens'.\n",
        "        '''\n",
        "        # SOLUTION\n",
        "        pred = self.model(batch)\n",
        "        loss = self.loss(pred[:,:-1,:], batch[:,1:,:])\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "        self.step += 1\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def train(self, steps=100_000):\n",
        "        '''\n",
        "        Trains the model, for `self.args.epochs` epochs. Also handles wandb initialization, and early stopping\n",
        "        for each epoch at `self.args.max_steps_per_epoch` steps.\n",
        "        '''\n",
        "        # Initialize Weights & Biases logging if needed\n",
        "        # wandb.init(project=self.args.wandb_project, name=self.args.wandb_name, config=self.args)\n",
        "\n",
        "        loss_history = []\n",
        "        with tqdm(total=steps, desc=\"Training Progress\", ascii=True) as pbar:\n",
        "            for i in range(steps):\n",
        "                # Simulating the generation of batches with varying lengths\n",
        "                # num_terms = t.randint(4, 10, (1,)).item() if i > steps / 5 else int((10 - 4) * (i / (steps / 5)) + 4)\n",
        "                num_terms = t.randint(4, 30, (1,)).item()\n",
        "                batch = generate_linear_recurrences(self.args.batch_size, length=num_terms, return_type='seq')\n",
        "                loss = self.training_step(batch)\n",
        "\n",
        "                # Update tqdm progress bar with loss information\n",
        "                pbar.update(1)\n",
        "                pbar.set_postfix_str(f\"Step: {i+1}, Loss: {loss.item():.7f}\")\n",
        "                if (i % 500 == 0):\n",
        "                    loss_history.append(loss.item())\n",
        "\n",
        "                # Optionally log metrics to Weights & Biases\n",
        "                # wandb.log({\"loss\": loss.item()}, step=i)\n",
        "        return loss_history\n",
        "\n",
        "    # Clean up Weights & Biases session after training is complete\n",
        "    # wandb.finish()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "6HHEQSWUagAy",
        "outputId": "9ee9ba6d-5e31-40e8-da90-d44b2e91184e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress:   0%|          | 376/100000 [00:22<1:37:58, 16.95it/s, Step: 376, Loss: 0.0014355]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-c2cfedaf9722>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerTrainingArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mloss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-783396a8a10a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, steps)\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mnum_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_linear_recurrences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_terms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'seq'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;31m# Update tqdm progress bar with loss information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-783396a8a10a>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = DemoTransformer(cfg).to(device)\n",
        "args = TransformerTrainingArgs()\n",
        "trainer = TransformerTrainer(args, model)\n",
        "loss_history = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_history[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAO0gUou3p3B",
        "outputId": "b47e1d3d-8d03-431a-dd6d-943c2d8b49ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.04710725788027e-06"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvXMQcUKagAy",
        "outputId": "56cf37f0-d4c7-4ec5-82f3-8fe6c9a4b745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-1.2819e-02,  1.1896e-02, -9.3517e-03,  ...,  1.2094e-02,\n",
            "           1.6456e-02,  1.1728e-04],\n",
            "         [-2.1908e-02,  1.2884e-02, -1.4077e-02,  ...,  1.4355e-02,\n",
            "           2.5902e-02, -1.0502e-02],\n",
            "         [-3.0997e-02,  1.3873e-02, -1.8802e-02,  ...,  1.6616e-02,\n",
            "           3.5348e-02, -2.1122e-02],\n",
            "         ...,\n",
            "         [-2.4913e-01,  3.7596e-02, -1.3221e-01,  ...,  7.0884e-02,\n",
            "           2.6206e-01, -2.7599e-01],\n",
            "         [-2.5822e-01,  3.8585e-02, -1.3693e-01,  ...,  7.3145e-02,\n",
            "           2.7151e-01, -2.8661e-01],\n",
            "         [-2.6731e-01,  3.9573e-02, -1.4166e-01,  ...,  7.5406e-02,\n",
            "           2.8095e-01, -2.9723e-01]]], device='cuda:0')\n",
            "tensor([[[-0.0056,  0.0110, -0.0052,  ...,  0.0115,  0.0067,  0.0101],\n",
            "         [-0.0226,  0.0127, -0.0155,  ...,  0.0156,  0.0264, -0.0135],\n",
            "         [-0.0321,  0.0134, -0.0199,  ...,  0.0190,  0.0358, -0.0231],\n",
            "         ...,\n",
            "         [-0.2475,  0.0350, -0.1288,  ...,  0.0727,  0.2608, -0.2825],\n",
            "         [-0.2565,  0.0360, -0.1334,  ...,  0.0750,  0.2702, -0.2933],\n",
            "         [-0.2656,  0.0370, -0.1379,  ...,  0.0773,  0.2796, -0.3041]]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "tensor(1.0931e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "vecs = generate_linear_recurrences(1, length=30, return_type='seq')\n",
        "vecs = vecs.to(device)\n",
        "print(vecs[:, 1:, :])\n",
        "print(model(vecs)[:, :-1, :])\n",
        "print(trainer.loss(model(vecs)[:, :-1, :], vecs[:, 1:, :]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hooked_model = HookedTransformer(cfg)\n",
        "print(hooked_model.state_dict().keys() - model.state_dict().keys())\n",
        "hooked_model.load_and_process_state_dict(state_dict=model.state_dict(),\n",
        "                                         fold_ln=False,\n",
        "                                         center_writing_weights=False,\n",
        "                                         center_unembed=False,\n",
        "                                         fold_value_biases=False,\n",
        "                                         refactor_factored_attn_matrices=False)\n",
        "\n",
        "#quick check lol\n",
        "t.testing.assert_close(hooked_model.embed.W_E, model.embed.W_E)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5USJI1NzhRYW",
        "outputId": "a7553da5-bc0c-4d03-bef1-dd1a8e0360b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'blocks.0.attn.mask', 'blocks.3.attn.mask', 'blocks.2.attn.mask', 'blocks.1.attn.mask'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vecs = generate_linear_recurrences(1, length=30, return_type='seq')\n",
        "print(vecs[:, 1:, :])\n",
        "result = hooked_model(vecs)\n",
        "print(result[:, :-1, :])\n",
        "print(trainer.loss(result[:, :-1, :], vecs[:, 1:, :]))\n",
        "\n",
        "t.testing.assert_close(result[:, :-1, :], model(vecs)[:, :-1, :])\n",
        "t.testing.assert_close(vecs[:, 1:, :], result[:, :-1, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "id": "kVgzNRtSh6eP",
        "outputId": "b22eda35-8b87-4ee6-b780-0ed9b5be452e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-9.4164e-03,  3.1504e-04,  2.8005e-02,  ..., -7.6020e-03,\n",
            "          -1.5232e-02,  1.1235e-02],\n",
            "         [-3.0781e-03, -1.2558e-02,  4.0473e-02,  ..., -5.5979e-05,\n",
            "          -2.1835e-02,  1.8238e-02],\n",
            "         [ 3.2603e-03, -2.5432e-02,  5.2940e-02,  ...,  7.4901e-03,\n",
            "          -2.8438e-02,  2.5242e-02],\n",
            "         ...,\n",
            "         [ 1.5538e-01, -3.3439e-01,  3.5216e-01,  ...,  1.8860e-01,\n",
            "          -1.8691e-01,  1.9333e-01],\n",
            "         [ 1.6172e-01, -3.4727e-01,  3.6462e-01,  ...,  1.9614e-01,\n",
            "          -1.9351e-01,  2.0034e-01],\n",
            "         [ 1.6806e-01, -3.6014e-01,  3.7709e-01,  ...,  2.0369e-01,\n",
            "          -2.0012e-01,  2.0734e-01]]], device='cuda:0')\n",
            "tensor([[[-0.0177,  0.0133,  0.0149,  ..., -0.0132, -0.0085,  0.0032],\n",
            "         [-0.0050, -0.0109,  0.0379,  ...,  0.0011, -0.0202,  0.0139],\n",
            "         [ 0.0015, -0.0248,  0.0511,  ...,  0.0104, -0.0276,  0.0224],\n",
            "         ...,\n",
            "         [ 0.1527, -0.3300,  0.3469,  ...,  0.1932, -0.1869,  0.1824],\n",
            "         [ 0.1587, -0.3426,  0.3589,  ...,  0.2008, -0.1935,  0.1890],\n",
            "         [ 0.1648, -0.3553,  0.3708,  ...,  0.2084, -0.2001,  0.1956]]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
            "tensor(1.2283e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Tensor-likes are not close!\n\nMismatched elements: 1156 / 1160 (99.7%)\nGreatest absolute difference: 0.01600748300552368 at index (0, 0, 12) (up to 1e-05 allowed)\nGreatest relative difference: 40.226444244384766 at index (0, 1, 24) (up to 1.3e-06 allowed)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-139-990f16c8504c>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/testing/_comparison.py\u001b[0m in \u001b[0;36massert_close\u001b[0;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_layout, check_stride, msg)\u001b[0m\n\u001b[1;32m   1521\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror_metas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;31m# TODO: compose all metas into one AssertionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1523\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merror_metas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Tensor-likes are not close!\n\nMismatched elements: 1156 / 1160 (99.7%)\nGreatest absolute difference: 0.01600748300552368 at index (0, 0, 12) (up to 1e-05 allowed)\nGreatest relative difference: 40.226444244384766 at index (0, 1, 24) (up to 1.3e-06 allowed)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits, cache = hooked_model.run_with_cache(vecs)"
      ],
      "metadata": {
        "id": "Ndlx6-fhnPd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot.imshow(\n",
        "    cache['pattern', 0].squeeze(dim=0),\n",
        "    x=np.arange(30),\n",
        "    y=np.arange(30),\n",
        "    facet_col=0, # This argument tells plotly which dimension to split into separate plots\n",
        "    facet_labels=[f\"Head {i}\" for i in range(6)], # Subtitles of separate plots\n",
        "    title=\"Attention Patterns in Layer 0\",\n",
        "    xaxis = \"Key\",\n",
        "    yaxis = \"Query\",\n",
        "    width=5000\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "h6DHFAG62J2C",
        "outputId": "8a387b98-1ff6-457e-8455-587aaef07913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"a8227724-255c-4bca-8e09-98fcd9e7ffc9\" class=\"plotly-graph-div\" style=\"height:525px; width:5000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a8227724-255c-4bca-8e09-98fcd9e7ffc9\")) {                    Plotly.newPlot(                        \"a8227724-255c-4bca-8e09-98fcd9e7ffc9\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"y\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"z\":[[1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.006977169308811426,0.9930227994918823,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0038802889175713062,0.01360240951180458,0.9825173020362854,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0032138649839907885,0.0025788741186261177,0.018227839842438698,0.9759793877601624,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.003967763390392065,0.005232664290815592,0.01563689112663269,0.09462901949882507,0.8805336356163025,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0050788153894245625,0.01142607256770134,0.013437625020742416,0.040781695395708084,0.11413770914077759,0.8151381611824036,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.003885305253788829,0.020742090418934822,0.014876974746584892,0.045746758580207825,0.027038341388106346,0.19590283930301666,0.6918076872825623,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0026486259885132313,0.008558753877878189,0.004534476902335882,0.009757938794791698,0.023463675752282143,0.04819924756884575,0.4709102213382721,0.4319270849227905,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.006369451992213726,0.018775686621665955,0.00281617627479136,0.005020070355385542,0.006836351938545704,0.020427437499165535,0.09251473844051361,0.7388778924942017,0.10836208611726761,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0023231771774590015,0.0021016860846430063,0.0005032984772697091,0.0016145810950547457,0.0033833766356110573,0.007184884045273066,0.037363503128290176,0.6133723855018616,0.04120756685733795,0.2909455895423889,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0016415211139246821,0.0016594704939052463,0.0003748440067283809,0.0010947983246296644,0.002812668215483427,0.006365287583321333,0.023033682256937027,0.3509165644645691,0.03991036117076874,0.10725989192724228,0.464930921792984,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0014364877715706825,0.0020239439327269793,0.002841006498783827,0.0069014206528663635,0.004204515367746353,0.013835063204169273,0.023417526856064796,0.03225839138031006,0.04601765796542168,0.03834879770874977,0.7784621715545654,0.05025307089090347,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0007660596747882664,0.0009602298378013074,0.0006138976896181703,0.0016448296373710036,0.0013635557843372226,0.004262861795723438,0.006627118214964867,0.019719358533620834,0.025321772322058678,0.01610666885972023,0.7390684485435486,0.03430801257491112,0.1492372304201126,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0003133589052595198,0.0005010439199395478,0.00044735328992828727,0.0014618636341765523,0.0006479366566054523,0.0025268015451729298,0.003459056606516242,0.0055303326807916164,0.015444176271557808,0.005921770352870226,0.5589893460273743,0.018711701035499573,0.08793485909700394,0.2981104552745819,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00018902707961387932,0.00091290392447263,0.0003872123488690704,0.0006509569357149303,0.00014023460971657187,0.0013312158407643437,0.0016386997886002064,0.0043998402543365955,0.015595166943967342,0.004114978946745396,0.4290342330932617,0.014976518228650093,0.07274408638477325,0.38223034143447876,0.07165456563234329,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0003347861929796636,0.0005150588694959879,0.0002937458048108965,0.0009005683241412044,0.0003627271216828376,0.0016661833506077528,0.0017189926002174616,0.006667057052254677,0.01714983396232128,0.007038962561637163,0.2590838074684143,0.018285740166902542,0.06462463736534119,0.18566563725471497,0.05318346992135048,0.3825087547302246,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0003232040617149323,0.0009588538086973131,0.0003507088986225426,0.0007314693066291511,0.00012277401401661336,0.00103369087446481,0.0004272388468962163,0.0022124978713691235,0.01644035056233406,0.003151272889226675,0.11140750348567963,0.010506563819944859,0.030185850337147713,0.10840500891208649,0.02533264085650444,0.6548647880554199,0.033545613288879395,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.001304655452258885,0.0016838583396747708,0.0006210558349266648,0.0014838685747236013,0.0002769649727270007,0.0014316037995740771,0.0005069869221188128,0.002620346611365676,0.021840184926986694,0.004389659035950899,0.05195951834321022,0.012845946475863457,0.02052984945476055,0.047699131071567535,0.01650925911962986,0.3095906972885132,0.02281797118484974,0.48188844323158264,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0012775432551279664,0.003460241248831153,0.0016050594858825207,0.0016220447141677141,0.00010801534517668188,0.0010606702417135239,0.00010791188105940819,0.0003740827669389546,0.013072866946458817,0.0009039035649038851,0.010314499028027058,0.003909651655703783,0.005281858611851931,0.014317499473690987,0.003831762121990323,0.24195511639118195,0.008108812384307384,0.6772856712341309,0.011402908712625504,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0008826901903375983,0.0027043053414672613,0.0008458755328319967,0.0008281730697490275,3.5112330806441605e-05,0.0004304804315324873,3.206800465704873e-05,0.00019242364214733243,0.009086637757718563,0.0004980545490980148,0.003657365683466196,0.002184466924518347,0.002203939016908407,0.00598406046628952,0.001757515361532569,0.16969430446624756,0.003951433580368757,0.7795942425727844,0.0052317664958536625,0.01020513940602541,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0006541582988575101,0.0022790622897446156,0.0005929100443609059,0.0005375550827011466,1.578115188749507e-05,0.0002492280618753284,1.408724801876815e-05,8.410969167016447e-05,0.006470084190368652,0.00026682429597713053,0.002428359119221568,0.0013310409849509597,0.0013489346019923687,0.003920340910553932,0.0009972535772249103,0.1521388739347458,0.0025449811946600676,0.8024097084999084,0.003567734733223915,0.0070157223381102085,0.011133313179016113,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00030617843731306493,0.001793837291188538,0.0003194871824234724,0.00024061276053544134,6.609481260966277e-06,0.00013656917144544423,8.375079232791904e-06,8.518061076756567e-05,0.00446758046746254,0.00021097691205795854,0.0014502076664939523,0.0009319689706899226,0.0009801681153476238,0.0032252036035060883,0.0008618325809948146,0.12088025361299515,0.002107704756781459,0.8370421528816223,0.0029814504086971283,0.006373640149831772,0.010049843229353428,0.005540147889405489,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0001834584109019488,0.0012108891969546676,0.00017343358194921166,0.00016706771566532552,3.958641173085198e-06,9.282850078307092e-05,6.167664651002269e-06,8.139877900248393e-05,0.0037102464120835066,0.0002063994761556387,0.001202413346618414,0.0007998589426279068,0.0008490283507853746,0.0029024737887084484,0.0007978625362738967,0.1033802330493927,0.0018766371067613363,0.8549128770828247,0.002739138202741742,0.005857208743691444,0.008966675959527493,0.004999087192118168,0.004880616441369057,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0006828611367382109,0.0010454790899530053,0.00021660538914147764,0.0003337620582897216,2.6392241124995053e-05,0.00024613557616248727,2.7700089049176313e-05,0.0003625745594035834,0.006965223699808121,0.0008197881979867816,0.003176947357133031,0.0023053379263728857,0.002206275472417474,0.004543405491858721,0.0018426749156787992,0.08107394725084305,0.0034588295966386795,0.4734285771846771,0.005204437300562859,0.00875428318977356,0.013102328404784203,0.00800135638564825,0.007325947750359774,0.3748491704463959,0.0,0.0,0.0,0.0,0.0,0.0],[0.0009981809416785836,0.0017283754423260689,0.000458185764728114,0.0005287444218993187,4.152377732680179e-05,0.0004082063678652048,3.795052180066705e-05,0.0006592522840946913,0.006888243369758129,0.0014680435415357351,0.0012701762607321143,0.002231273800134659,0.0018872590735554695,0.0029415662866085768,0.001772475428879261,0.03526077792048454,0.0034397593699395657,0.4632427394390106,0.004017311614006758,0.006787387654185295,0.007509625982493162,0.005086199846118689,0.00479438342154026,0.40873366594314575,0.037808749824762344,0.0,0.0,0.0,0.0,0.0],[0.0005962471477687359,0.0012594771105796099,0.00046406162437051535,0.00034640508238226175,3.006360748258885e-05,0.0003798191319219768,3.0693885491928086e-05,0.0005499690305441618,0.005134604871273041,0.0011932299239560962,0.0008943469729274511,0.0015176654560491443,0.0017089294269680977,0.0026274099946022034,0.0015600990736857057,0.02593304216861725,0.003160289954394102,0.4088301956653595,0.003406688803806901,0.0061185322701931,0.006534470710903406,0.004583720117807388,0.004235837142914534,0.4739757180213928,0.030013354495167732,0.014915158040821552,0.0,0.0,0.0,0.0],[0.0003592083230614662,0.000819466426037252,0.00030888713081367314,0.00020525675790850073,2.1334908524295315e-05,0.0003073022235184908,2.5153269234579057e-05,0.0005794821190647781,0.0040114568546414375,0.0011783487861976027,0.0007451581186614931,0.0012425598688423634,0.0016703089931979775,0.002475800458341837,0.0015174326254054904,0.01968473754823208,0.0030584579799324274,0.36770954728126526,0.0032468948047608137,0.005775321740657091,0.005984761752188206,0.004357980564236641,0.003966194577515125,0.5212237238883972,0.023344002664089203,0.011933240108191967,0.014247996732592583,0.0,0.0,0.0],[0.0002260984038002789,0.0005405015544965863,0.00018416527018416673,0.00011602371523622423,1.5720215742476285e-05,0.0002460417163092643,2.3812250219634734e-05,0.0007634166977368295,0.0032967098522931337,0.00134889199398458,0.0006803239812143147,0.0011138669215142727,0.0017612837255001068,0.002512802369892597,0.0016863136552274227,0.015041815117001534,0.0031710155308246613,0.3212507665157318,0.0033810806926339865,0.005929048638790846,0.006029633339494467,0.004543183837085962,0.004114788956940174,0.5691143870353699,0.018462099134922028,0.009961798787117004,0.011555749922990799,0.012928633019328117,0.0,0.0],[0.00010594172636047006,0.0002729687839746475,9.740783571032807e-05,6.496711284853518e-05,1.1651438398985192e-05,0.00019892056297976524,2.4105876946123317e-05,0.0010143573163077235,0.002600098727270961,0.0015624050283804536,0.000697779527399689,0.000999646494165063,0.002043865853920579,0.0028642388060688972,0.0020336087327450514,0.011634576134383678,0.0035053580068051815,0.2624914050102234,0.0037538064643740654,0.006445247679948807,0.006437927484512329,0.005113916005939245,0.004636269528418779,0.6297285556793213,0.014632100239396095,0.008466007187962532,0.009430297650396824,0.01026988960802555,0.0088626928627491,0.0],[0.01682877540588379,0.021183578297495842,0.027565987780690193,0.023498734459280968,0.015419847331941128,0.0249092485755682,0.015041744336485863,0.01824989728629589,0.02947547659277916,0.02178817242383957,0.02921310067176819,0.025858106091618538,0.03113575279712677,0.03541886433959007,0.02751445770263672,0.04642508178949356,0.032672733068466187,0.061479777097702026,0.03295433521270752,0.03440301865339279,0.03556298092007637,0.03495849668979645,0.03393394127488136,0.0665375292301178,0.046080008149147034,0.04193735122680664,0.04322677105665207,0.04372374713420868,0.04311488941311836,0.039887551218271255]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"1\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"y\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"z\":[[1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0032174831721931696,0.9967825412750244,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0040359655395150185,0.010101743042469025,0.9858621954917908,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0039322152733802795,0.0035651165526360273,0.022765111178159714,0.9697375297546387,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.003513155272230506,0.0031708732713013887,0.005620831623673439,0.18314342200756073,0.8045517206192017,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0016888220561668277,0.00820818543434143,0.012829583138227463,0.0677526667714119,0.21641522645950317,0.6931055188179016,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0020992248319089413,0.005934491753578186,0.006036609876900911,0.030708815902471542,0.04908279329538345,0.43478459119796753,0.4713534712791443,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.003057359717786312,0.008491985499858856,0.0035550822503864765,0.01788666658103466,0.046781886368989944,0.12416299432516098,0.32856062054634094,0.4675033390522003,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.006648519076406956,0.014492101036012173,0.003745431313291192,0.014598753303289413,0.02405075542628765,0.06258920580148697,0.12597955763339996,0.17195141315460205,0.5759443640708923,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0012972481781616807,0.0008887136355042458,0.00039082675357349217,0.0028070122934877872,0.004373899661004543,0.00997119303792715,0.0182309839874506,0.03152740001678467,0.8293303847312927,0.10118225961923599,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0004293647943995893,0.0003450024814810604,0.0002728876715991646,0.0012174155563116074,0.0020338876638561487,0.00509336544200778,0.007644428871572018,0.013241278007626534,0.5333209037780762,0.04812122508883476,0.3882802426815033,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0006563352071680129,0.0007547815330326557,0.000460169481812045,0.0017231353558599949,0.0020539886318147182,0.005367731675505638,0.0067659891210496426,0.021683596074581146,0.24857290089130402,0.04054275527596474,0.6163253784179688,0.055093228816986084,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0008109459886327386,0.0005383701645769179,0.00045321695506572723,0.0015283358516171575,0.0018026522593572736,0.005197384860366583,0.005420971661806107,0.01766357384622097,0.10671758651733398,0.035961050540208817,0.4894479811191559,0.039895199239254,0.29456260800361633,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00012363317364361137,0.00021756271598860621,0.0002013136981986463,0.0004252890357747674,0.0004990334855392575,0.0016919751651585102,0.0016255623195320368,0.007034570910036564,0.06507496535778046,0.012575764209032059,0.3994482457637787,0.028536973521113396,0.33854734897613525,0.14399774372577667,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00029476682539097965,0.0005160022410564125,0.00013148172001820058,0.00024814895004965365,0.00024142471374943852,0.001360381138511002,0.0011188833741471171,0.008097830228507519,0.04282921925187111,0.012804209254682064,0.29580527544021606,0.017108986154198647,0.15302222967147827,0.0840434655547142,0.3823777735233307,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00017386047693435103,0.00037675071507692337,0.00027102691819891334,0.00046638271305710077,0.00043586973333731294,0.0015054545365273952,0.0011568187037482858,0.006577905733138323,0.022735731676220894,0.013099576346576214,0.2707875370979309,0.0230912696570158,0.1114635095000267,0.0754273310303688,0.1803315430879593,0.2920995056629181,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.000269748386926949,0.0007749987416900694,0.0002923231804743409,0.0004502931551542133,0.00026598997646942735,0.0011174710234627128,0.0006741970428265631,0.006712254136800766,0.012929869815707207,0.009756776504218578,0.20677392184734344,0.01933610439300537,0.06543534249067307,0.06503037363290787,0.12767793238162994,0.422188937664032,0.06031343713402748,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0007672638166695833,0.003470838535577059,0.001976744271814823,0.0009165840456262231,0.0005798917845822871,0.001651278929784894,0.0007704115705564618,0.008424176834523678,0.0037810264620929956,0.006835604086518288,0.12614549696445465,0.01920754462480545,0.031688231974840164,0.04996452108025551,0.04285283759236336,0.5171482563018799,0.036193933337926865,0.1476253718137741,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0016480969497933984,0.004570184275507927,0.0020739755127578974,0.0009958329610526562,0.000496437365654856,0.001584211946465075,0.0006424974417313933,0.007179312873631716,0.005723593756556511,0.0053618792444467545,0.056817974895238876,0.014530271291732788,0.02574240043759346,0.03653968870639801,0.03940832242369652,0.4350165128707886,0.045438092201948166,0.2412172555923462,0.0750134289264679,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.001445526140742004,0.004163085483014584,0.0016726120375096798,0.0007390445680357516,0.00032615161035209894,0.0015071751549839973,0.0005556338583119214,0.006147594191133976,0.005033203866332769,0.004650632850825787,0.038609862327575684,0.012171084992587566,0.01940157450735569,0.029805243015289307,0.0357542522251606,0.33906930685043335,0.040944162756204605,0.3065832555294037,0.0701739713549614,0.08124667406082153,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0013486766256392002,0.004716814495623112,0.0012517578434199095,0.0005788502749055624,0.00020402850350365043,0.0011869593290612102,0.0004260143032297492,0.005042343400418758,0.004121815320104361,0.003887216094881296,0.026099316775798798,0.009514817968010902,0.013186309486627579,0.02199213020503521,0.029457420110702515,0.2642764449119568,0.03378812596201897,0.36153796315193176,0.060263317078351974,0.06333352625370026,0.09378618746995926,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.000982465106062591,0.0032860932406038046,0.0008706565713509917,0.0003946626093238592,0.00013281214341986924,0.0009221768123097718,0.0003156901802867651,0.0034952901769429445,0.005155617371201515,0.0032493146136403084,0.018620718270540237,0.0077033513225615025,0.012003917247056961,0.01740141399204731,0.028534578159451485,0.18292589485645294,0.03070010431110859,0.4111175239086151,0.05592762678861618,0.06206030398607254,0.0790197029709816,0.07518009841442108,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0005047098966315389,0.0017300315666943789,0.0003980889159720391,0.00024036754621192813,8.187068306142464e-05,0.0006320906686596572,0.0002544937306083739,0.002629163907840848,0.005155366379767656,0.0025761015713214874,0.017015406861901283,0.006213650107383728,0.011989208869636059,0.015841422602534294,0.02839299477636814,0.153985857963562,0.02871842123568058,0.39007601141929626,0.054513245820999146,0.061390470713377,0.07733555138111115,0.07914046943187714,0.06118512898683548,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0004731988301500678,0.0022913047578185797,0.0010762393940240145,0.0003685255360323936,0.0001610712060937658,0.0006937527214176953,0.00023659795988351107,0.0030485845636576414,0.0016883248463273048,0.0026542518753558397,0.02989516779780388,0.00778844952583313,0.009385643526911736,0.016759628430008888,0.015964852645993233,0.21252533793449402,0.016031356528401375,0.12589004635810852,0.0429835319519043,0.05218949541449547,0.08823224157094955,0.06522365659475327,0.040796127170324326,0.2636426091194153,0.0,0.0,0.0,0.0,0.0,0.0],[0.0007175172795541584,0.0026753901038318872,0.000928503111936152,0.000659440120216459,0.0003107334196101874,0.0013664279831573367,0.0006818770198151469,0.004024852067232132,0.005548098590224981,0.00426276633515954,0.019511783495545387,0.009669437073171139,0.013385362923145294,0.01771431975066662,0.0228201262652874,0.100021131336689,0.024283379316329956,0.1837594360113144,0.043564002960920334,0.04685972258448601,0.052949208766222,0.05163057893514633,0.042181845754384995,0.2614406943321228,0.08903338015079498,0.0,0.0,0.0,0.0,0.0],[0.0006306866416707635,0.0017007440328598022,0.0007227307069115341,0.0005154401296749711,0.00026749123935587704,0.0012268777936697006,0.0006353470962494612,0.002917625941336155,0.009355690330266953,0.003687589894980192,0.01337912306189537,0.007779550738632679,0.014986129477620125,0.014577476307749748,0.023653773590922356,0.06261231005191803,0.025785161182284355,0.18895529210567474,0.03702883422374725,0.043769337236881256,0.043956924229860306,0.04855402931571007,0.04213704541325569,0.27395519614219666,0.07515539973974228,0.06205415353178978,0.0,0.0,0.0,0.0],[0.00033814701600931585,0.001072916784323752,0.0004552413884084672,0.00035102423862554133,0.00018984309281222522,0.0008938769460655749,0.00046774334623478353,0.0021452002692967653,0.008586781099438667,0.002988645574077964,0.012251663021743298,0.006565336138010025,0.014184055849909782,0.012736659497022629,0.02164233662188053,0.051702830940485,0.02253088541328907,0.1719536930322647,0.0340275876224041,0.0418374240398407,0.03934093192219734,0.04583781957626343,0.04015976935625076,0.27624839544296265,0.07002571225166321,0.058346930891275406,0.06311852484941483,0.0,0.0,0.0],[0.0001512379531050101,0.000561209162697196,0.00022538399207405746,0.00019193570187781006,0.00011574116797419265,0.0005699295434169471,0.0003168421098962426,0.0014283467317000031,0.008279943838715553,0.002240526955574751,0.010707689449191093,0.005092435050755739,0.013760251924395561,0.01069381833076477,0.019955787807703018,0.04036055505275726,0.019478892907500267,0.15316449105739594,0.03065984882414341,0.04009101912379265,0.03550645336508751,0.04452073574066162,0.03949498012661934,0.28498053550720215,0.06488524377346039,0.05439106374979019,0.058513887226581573,0.05966119468212128,0.0,0.0],[3.4991357097169384e-05,0.00016427012451458722,7.230167102534324e-05,7.561528764199466e-05,5.2180348575348035e-05,0.00026701384922489524,0.00016213265189435333,0.0007227637688629329,0.0073882355354726315,0.0013509212294593453,0.009490018710494041,0.003509817412123084,0.014085466973483562,0.0087435869500041,0.017620956525206566,0.029947733506560326,0.016040116548538208,0.12465985119342804,0.026676403358578682,0.03888053074479103,0.03260989114642143,0.04540369287133217,0.04062345251441002,0.3114725947380066,0.06214067339897156,0.05324443802237511,0.056987352669239044,0.057727571576833725,0.039845455437898636,0.0],[0.008851828053593636,0.011897126212716103,0.012692082673311234,0.012095065787434578,0.011466007679700851,0.015150058083236217,0.013695928268134594,0.018798893317580223,0.025406692177057266,0.021122125908732414,0.03635266423225403,0.02888074889779091,0.03704283758997917,0.03467797487974167,0.035892732441425323,0.04387661814689636,0.034408051520586014,0.05049546808004379,0.040742915123701096,0.04263167455792427,0.04208068549633026,0.043957602232694626,0.041880909353494644,0.06150481849908829,0.04702705144882202,0.04726853594183922,0.04767383262515068,0.0473884753882885,0.04387429729104042,0.041166309267282486]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"2\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"y\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"z\":[[1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0035556501243263483,0.9964444041252136,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.004925928544253111,0.009678812697529793,0.9853953123092651,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.010542954318225384,0.006416696589440107,0.021864956244826317,0.9611755013465881,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.038481730967760086,0.005202668718993664,0.008424751460552216,0.0771920308470726,0.8706987500190735,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.01794901117682457,0.003493382828310132,0.005400774534791708,0.0140969417989254,0.36580467224121094,0.5932552814483643,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.05304906889796257,0.01901024393737316,0.007682671304792166,0.009381450712680817,0.05480024591088295,0.12445109337568283,0.7316252589225769,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0015275526093319058,0.0006239139474928379,0.0004720489669125527,0.0008086345042102039,0.010247554630041122,0.010304168798029423,0.8314475417137146,0.1445685625076294,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.036704760044813156,0.03812458738684654,0.004023168236017227,0.004201916977763176,0.004935746546834707,0.015588561072945595,0.020157061517238617,0.15468399226665497,0.7215802073478699,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.015222723595798016,0.0065139043144881725,0.0017174852546304464,0.004651146475225687,0.008927101269364357,0.01246078684926033,0.021066829562187195,0.0449846126139164,0.5468546152114868,0.33760082721710205,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0012315191561356187,0.000331696355715394,0.0001277747069252655,0.0002502982970327139,0.0006936593563295901,0.0014224816113710403,0.004280606284737587,0.01761884056031704,0.3003162145614624,0.535103440284729,0.1386234611272812,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.003989252727478743,0.0020468775182962418,0.0007027212996035814,0.0015633396105840802,0.0013561277883127332,0.0024064488243311644,0.0031274696812033653,0.020369725301861763,0.12647393345832825,0.31275734305381775,0.09483371675014496,0.4303729832172394,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.002286357805132866,0.0007828707457520068,0.0004492275766097009,0.0007228687172755599,0.0015327837318181992,0.0021451138891279697,0.005173174198716879,0.016208114102482796,0.0788881704211235,0.16631148755550385,0.05851338431239128,0.3480769991874695,0.31890952587127686,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00033988914219662547,0.00011004114639945328,0.00012213326408527792,0.00019153457833454013,0.000451825704658404,0.0006291797617450356,0.002053022850304842,0.006095468997955322,0.03552112355828285,0.09348081052303314,0.04015234857797623,0.28707796335220337,0.422652930021286,0.11112170666456223,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0006067964131943882,0.00020692477119155228,9.585863153915852e-05,5.198663711780682e-05,0.00022336059191729873,0.0005509632756002247,0.001294913818128407,0.004593635909259319,0.028377853333950043,0.03815004602074623,0.029758721590042114,0.1328449547290802,0.42295965552330017,0.07462502270936966,0.26565930247306824,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00014737392484676093,7.361661118920892e-05,9.511337702861056e-05,6.053493416402489e-05,0.00010727419430622831,0.0002635384735185653,0.0003765999572351575,0.002454192843288183,0.008909896947443485,0.021169360727071762,0.022278932854533195,0.080806203186512,0.40681877732276917,0.07114501297473907,0.20779582858085632,0.17749769985675812,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0004289862117730081,0.00028015984571538866,0.0002142781304428354,9.738637891132385e-05,0.00021804383140988648,0.0006260210648179054,0.0006073179538361728,0.004223471041768789,0.011066782288253307,0.02050163410604,0.022975444793701172,0.06533797085285187,0.25934481620788574,0.06358656287193298,0.16761170327663422,0.18706944584846497,0.19580990076065063,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0010892996797338128,0.0006362576386891305,0.0007393013220280409,0.00034175641485489905,0.0005481534171849489,0.001237855409272015,0.0010070758871734142,0.005330551881343126,0.008489674888551235,0.013229060918092728,0.025283517315983772,0.04010013863444328,0.19930219650268555,0.05369899049401283,0.09942879527807236,0.13677194714546204,0.10674377530813217,0.3060216009616852,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.002086793538182974,0.0016621928662061691,0.0009759318782016635,0.0003296389477327466,0.0007240906124934554,0.0021271989680826664,0.0008431817404925823,0.006406253203749657,0.011016782373189926,0.011263543739914894,0.019350694492459297,0.025111880153417587,0.10529419779777527,0.0348881334066391,0.0653008446097374,0.11582154035568237,0.10631871223449707,0.3484848737716675,0.1419934779405594,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.002156756119802594,0.0015406013699248433,0.0009276375640183687,0.00019290446653030813,0.00044419956975616515,0.0017900909297168255,0.0005797696067020297,0.004821993410587311,0.006790444254875183,0.0060761165805161,0.014023303985595703,0.015486938878893852,0.08404513448476791,0.026424096897244453,0.04692266508936882,0.09812446683645248,0.07681063562631607,0.34484726190567017,0.12108296155929565,0.14691197872161865,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.002188443671911955,0.0021971201058477163,0.0008868383010849357,0.00014294873108156025,0.00022183290275279433,0.0011958134127780795,0.0002436923678033054,0.0034406466875225306,0.004104030784219503,0.004267984535545111,0.009103110991418362,0.009182998910546303,0.05585651099681854,0.017975272610783577,0.03323257714509964,0.07658583670854568,0.0605272613465786,0.33914923667907715,0.09644672274589539,0.1329459697008133,0.15010523796081543,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0013851687544956803,0.0018728413851931691,0.0005291625275276601,8.290825644508004e-05,0.00012400791456457227,0.0007477364270016551,0.0001296999689657241,0.0022994617465883493,0.003626476740464568,0.003340344410389662,0.005799745209515095,0.006885559298098087,0.0357038788497448,0.012352964840829372,0.025349121540784836,0.060394324362277985,0.05061386898159981,0.31966298818588257,0.08202697336673737,0.13927923142910004,0.15709824860095978,0.09069526940584183,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0005117349210195243,0.0009274154435843229,0.00014852055755909532,2.9729191737715155e-05,3.559529795893468e-05,0.00025060848565772176,4.880562119069509e-05,0.0011610595975071192,0.002430780092254281,0.002484940690919757,0.0034154157619923353,0.005287740845233202,0.02685932256281376,0.00855539832264185,0.020761344581842422,0.044548116624355316,0.04240848869085312,0.29049962759017944,0.0769091472029686,0.14244437217712402,0.16849598288536072,0.09327379614114761,0.06851205974817276,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0005538139957934618,0.000451236090157181,0.00038261388544924557,9.348411549581215e-05,0.00013791359378956258,0.0005088994512334466,0.00018823766731657088,0.0018627074314281344,0.0022246092557907104,0.002822662005200982,0.007213774137198925,0.008292032405734062,0.05413404479622841,0.015465761534869671,0.02766020968556404,0.055717431008815765,0.03785562142729759,0.17306748032569885,0.06718192994594574,0.07304303348064423,0.08642309904098511,0.058890871703624725,0.042143914848566055,0.283684641122818,0.0,0.0,0.0,0.0,0.0,0.0],[0.0007846857188269496,0.0014012515312060714,0.0006272817845456302,0.00019760767463594675,0.00017173348169308156,0.0007602592231705785,0.00015734935004729778,0.0021095285192131996,0.0031589784193784,0.0034287802409380674,0.0059952884912490845,0.006378193851560354,0.03162481263279915,0.01239653117954731,0.021250825375318527,0.03875919058918953,0.03589410334825516,0.13780748844146729,0.052026014775037766,0.07357104867696762,0.07924411445856094,0.05441093444824219,0.042552389204502106,0.32571035623550415,0.06958121806383133,0.0,0.0,0.0,0.0,0.0],[0.0007773134857416153,0.0016290757339447737,0.0005661011091433465,0.00018341281975153834,0.00016364479961339384,0.0007597524672746658,0.00011754551087506115,0.0018331027822569013,0.003844072576612234,0.0034070841502398252,0.0047985948622226715,0.005203029606491327,0.021797379478812218,0.009173015132546425,0.016895754262804985,0.02974696084856987,0.032782867550849915,0.11687188595533371,0.04100242257118225,0.07206372916698456,0.07553888112306595,0.05042653903365135,0.040034227073192596,0.34543296694755554,0.06939289718866348,0.05555780231952667,0.0,0.0,0.0,0.0],[0.0003715522470884025,0.0009935182752087712,0.0003147437528241426,0.00010707737965276465,8.668140799272805e-05,0.0004313038371037692,6.297762593021616e-05,0.0011951311025768518,0.002705456456169486,0.002575441263616085,0.0035273656249046326,0.004071277100592852,0.01830606535077095,0.007380008697509766,0.014280491508543491,0.024883396923542023,0.028367875143885612,0.10405624657869339,0.03612471744418144,0.06707567721605301,0.07015553116798401,0.04553660750389099,0.03622649237513542,0.3610718846321106,0.06551717966794968,0.051284242421388626,0.05329104885458946,0.0,0.0,0.0],[0.00016171710740309209,0.0004890807322226465,0.00012949427764397115,4.850250479648821e-05,3.8929243601160124e-05,0.00020769253023900092,3.169936462654732e-05,0.0007008818793110549,0.0019895718432962894,0.0019779379945248365,0.002421322511509061,0.003243969287723303,0.01516505517065525,0.005582992918789387,0.012107538990676403,0.019700970500707626,0.024187499657273293,0.09085911512374878,0.03228609263896942,0.06324951350688934,0.06770717352628708,0.042782220989465714,0.03400617092847824,0.37505972385406494,0.06176485866308212,0.04813162237405777,0.04986335337162018,0.04610535502433777,0.0,0.0],[4.193613494862802e-05,0.00015594378055538982,3.772666605073027e-05,1.8347867808188312e-05,1.4889806152496021e-05,8.021979738259688e-05,1.4964186448196415e-05,0.00035845953971147537,0.0013999944785609841,0.0014869882725179195,0.0016277479007840157,0.002767047379165888,0.013043385930359364,0.004339123610407114,0.010606680996716022,0.015413621440529823,0.020969651639461517,0.0752122700214386,0.02935696206986904,0.060831084847450256,0.06719476729631424,0.041326455771923065,0.03327074646949768,0.39674586057662964,0.05928244814276695,0.0466996505856514,0.04798457771539688,0.04376520216464996,0.025953300297260284,0.0],[0.009151317179203033,0.012839245609939098,0.015966219827532768,0.01200313214212656,0.010868561454117298,0.014061519876122475,0.010126722045242786,0.019034726545214653,0.01963244378566742,0.025155339390039444,0.025669027119874954,0.030226875096559525,0.03992576524615288,0.033693987876176834,0.03807664290070534,0.039669185876846313,0.040068723261356354,0.04948696866631508,0.04579884558916092,0.04806126281619072,0.047456420958042145,0.042601171880960464,0.04112100973725319,0.06399420648813248,0.04614337533712387,0.04616923630237579,0.045854147523641586,0.044512633234262466,0.040340255945920944,0.042291052639484406]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"3\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"y\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"z\":[[1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0022608344443142414,0.9977391958236694,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.003261416219174862,0.012353096157312393,0.9843854308128357,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.012479817494750023,0.007244431879371405,0.01755407080054283,0.9627217054367065,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.010846531949937344,0.004895227495580912,0.007351697888225317,0.18171723186969757,0.795189380645752,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.006140583194792271,0.012227960862219334,0.00890482496470213,0.03947523981332779,0.3187543451786041,0.6144970655441284,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.020717499777674675,0.01569226197898388,0.014321799390017986,0.04666481539607048,0.07157963514328003,0.13772398233413696,0.6933000683784485,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0024240477941930294,0.0032517872750759125,0.0009156906162388623,0.004793827887624502,0.02363714762032032,0.022904152050614357,0.7092302441596985,0.23284301161766052,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.010228056460618973,0.019934115931391716,0.006155658513307571,0.009818916209042072,0.020796317607164383,0.038128744810819626,0.1579698771238327,0.1544645130634308,0.5825037956237793,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0035315004643052816,0.0015790903707966208,0.0005247489898465574,0.002600975800305605,0.0051896353252232075,0.007018126081675291,0.0663202777504921,0.024915073066949844,0.6800125241279602,0.20830808579921722,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0007479939376935363,0.00037539275945164263,0.00013473549915943295,0.0005405109259299934,0.0009225725661963224,0.0017015499761328101,0.008152475580573082,0.013411554507911205,0.34836843609809875,0.4339788556098938,0.191665917634964,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.002198152942582965,0.000959026045165956,0.0010108099086210132,0.0036294094752520323,0.0026894703041762114,0.003922026138752699,0.006160056218504906,0.01460559293627739,0.1320132315158844,0.29844239354133606,0.13376928865909576,0.4006006121635437,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0012693093158304691,0.0010247755562886596,0.0007346458151005208,0.0013470792910084128,0.001966227777302265,0.0029672763776034117,0.005791475996375084,0.013843076303601265,0.065970279276371,0.15587341785430908,0.09285972267389297,0.43121710419654846,0.22513560950756073,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00029801850905641913,0.0002650173846632242,0.000290123833110556,0.0005327554536052048,0.0006573765422217548,0.0008814281318336725,0.001561748911626637,0.005877165123820305,0.018622277304530144,0.07826374471187592,0.06277381628751755,0.4497750997543335,0.25819024443626404,0.12201119214296341,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00031084768124856055,0.0004763699835166335,0.0003045472549274564,0.00023236655397340655,0.0005224509513936937,0.0007415910949930549,0.0022994275204837322,0.006212230306118727,0.010018108412623405,0.028986021876335144,0.04291249066591263,0.3519953489303589,0.20707149803638458,0.10748794674873352,0.24042879045009613,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[7.556014315923676e-05,0.00016139271610882133,0.0001992312609218061,0.00015857393736951053,0.00024561688769608736,0.00034307496389374137,0.0005225525237619877,0.0027338527143001556,0.0033849533647298813,0.022205935791134834,0.02829054556787014,0.3341546356678009,0.1270769089460373,0.07623687386512756,0.15015146136283875,0.254058837890625,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0001935176260303706,0.0004345905617810786,0.0002878738450817764,0.00029660266591235995,0.00045370921725407243,0.0007210143376141787,0.0011264861095696688,0.004180185962468386,0.008567696437239647,0.032015759497880936,0.030273837968707085,0.20399627089500427,0.09755179286003113,0.06483333557844162,0.14239399135112762,0.1920429915189743,0.22063037753105164,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0008368548005819321,0.0015546070644631982,0.0016732674557715654,0.0009216070757247508,0.001161488937214017,0.001460243365727365,0.0015161115443333983,0.006547478027641773,0.0037387986667454243,0.017284134402871132,0.027679264545440674,0.13722443580627441,0.08770682662725449,0.05495655909180641,0.07189241796731949,0.13791608810424805,0.27031219005584717,0.17561763525009155,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.001984535250812769,0.002339255064725876,0.0017441821983084083,0.0009173356229439378,0.0008990782080218196,0.0016075194580480456,0.0008862626273185015,0.005617240909487009,0.0055498527362942696,0.019327329471707344,0.022452084347605705,0.05704135447740555,0.07266602665185928,0.03385734558105469,0.0519164502620697,0.09198660403490067,0.33782172203063965,0.17688784003257751,0.11449795216321945,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0013060006313025951,0.002749335952103138,0.0018394091166555882,0.0005333881126716733,0.0006093290285207331,0.001262925798073411,0.0006779265240766108,0.0046175820752978325,0.0026540528051555157,0.009906364604830742,0.015739191323518753,0.04490627348423004,0.052977919578552246,0.02888689562678337,0.0396357998251915,0.08490567654371262,0.32069098949432373,0.18181100487709045,0.10463467985391617,0.09965527057647705,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.001098558772355318,0.003601781325414777,0.001860142918303609,0.0003840548451989889,0.00035673551610670984,0.0009508535149507225,0.0003210673457942903,0.0032112079206854105,0.0015074503608047962,0.0072002592496573925,0.01095416210591793,0.03232226148247719,0.0361856110394001,0.02145993709564209,0.027696643024683,0.07102426141500473,0.299091100692749,0.19524718821048737,0.08796709775924683,0.08494309335947037,0.11261656880378723,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0008225888595916331,0.0031101892236620188,0.0009104186901822686,0.0001810591493267566,0.00016638451779726893,0.0005965742748230696,0.00020643920288421214,0.002116486197337508,0.0015346675645560026,0.005656267050653696,0.007528887130320072,0.019275471568107605,0.026190567761659622,0.014570312574505806,0.022909468039870262,0.05568232387304306,0.27330371737480164,0.2009894996881485,0.07489437609910965,0.08185272663831711,0.10777021944522858,0.09973132610321045,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0003536646836437285,0.0014369938289746642,0.0003240389924030751,9.105226490646601e-05,7.405375072266906e-05,0.000285595771856606,0.00012369357864372432,0.0012508011423051357,0.00122439069673419,0.004674876574426889,0.005780105944722891,0.0170049536973238,0.022427890449762344,0.011646095663309097,0.021138763055205345,0.04945624619722366,0.23775602877140045,0.19474710524082184,0.07251191884279251,0.07874751836061478,0.1080879271030426,0.0968741774559021,0.07398214936256409,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.000326030160067603,0.001143267611041665,0.0007250865455716848,0.00020918391237501055,0.00023891840828582644,0.0004703158338088542,0.0003059938026126474,0.0020609209313988686,0.000973787740804255,0.004859308712184429,0.008123462088406086,0.03707505390048027,0.026158975437283516,0.017657451331615448,0.023435218259692192,0.05682997778058052,0.1398502141237259,0.10996013879776001,0.06893278658390045,0.05620570480823517,0.08174365013837814,0.061854083091020584,0.04712233319878578,0.2537381649017334,0.0,0.0,0.0,0.0,0.0,0.0],[0.0004898965707980096,0.0020506796427071095,0.0008757512550801039,0.00032052607275545597,0.0002957551332656294,0.0007878932519815862,0.00041937659261748195,0.0022937932517379522,0.0021745695266872644,0.006572118494659662,0.007913719862699509,0.021721234545111656,0.020432284101843834,0.015131672844290733,0.022952331230044365,0.044074896723032,0.09521374106407166,0.12147637456655502,0.05598008260130882,0.05658944323658943,0.0663149282336235,0.056742243468761444,0.046788979321718216,0.2803901135921478,0.07199762016534805,0.0,0.0,0.0,0.0,0.0],[0.0005277311429381371,0.0018640127964317799,0.0006881470908410847,0.0002372212038608268,0.00021627030218951404,0.0007212995551526546,0.00035567660233937204,0.001873142085969448,0.00330174108967185,0.006965231150388718,0.006600500550121069,0.013110988773405552,0.01674933172762394,0.011068174615502357,0.02089725062251091,0.03331388160586357,0.07676851004362106,0.11410259455442429,0.04485796391963959,0.05470738187432289,0.05998411029577255,0.05576315149664879,0.0466889813542366,0.2951129972934723,0.06934235990047455,0.06418132036924362,0.0,0.0,0.0,0.0],[0.00025491206906735897,0.0012285555712878704,0.0004117053176742047,0.00014348448894452304,0.0001396608422510326,0.0004965952830389142,0.0002567658666521311,0.0013399407034739852,0.0027525529731065035,0.005956146400421858,0.0052897571586072445,0.011860311031341553,0.013469322584569454,0.009338470175862312,0.019154248759150505,0.029644621536135674,0.05696830153465271,0.10840819031000137,0.04060142859816551,0.05059569329023361,0.05387783795595169,0.04784022271633148,0.040725525468587875,0.3017283082008362,0.06318236142396927,0.060230035334825516,0.07410505414009094,0.0,0.0,0.0],[0.0001138579536927864,0.0006504110642708838,0.00018161017214879394,7.004096551099792e-05,7.459669723175466e-05,0.0002882562985178083,0.00017762910283636302,0.0008559813140891492,0.0025198906660079956,0.004998268559575081,0.0040139066986739635,0.009946392849087715,0.010825126431882381,0.007351001724600792,0.01764591597020626,0.024936571717262268,0.04174811393022537,0.09963860362768173,0.03617436811327934,0.04724747687578201,0.049724627286195755,0.0425727441906929,0.037268172949552536,0.3072097599506378,0.057910773903131485,0.05671543627977371,0.0689481794834137,0.07019221782684326,0.0,0.0],[2.7393773052608594e-05,0.0001905742974486202,4.8351892473874614e-05,2.390736153756734e-05,2.8288315661484376e-05,0.00011670511594275013,9.464891627430916e-05,0.00042260740883648396,0.0020399128552526236,0.0038598254323005676,0.0027884922455996275,0.008501422591507435,0.008623950183391571,0.005448599811643362,0.016395963728427887,0.02056877128779888,0.028480203822255135,0.08916625380516052,0.03233971446752548,0.044305652379989624,0.04696633294224739,0.03788163512945175,0.03435009345412254,0.32772740721702576,0.05319539085030556,0.05587337538599968,0.0667489692568779,0.06730189174413681,0.046483561396598816,0.0],[0.009493118152022362,0.01474544033408165,0.01901305466890335,0.012068930082023144,0.012537977658212185,0.014791774563491344,0.012453918345272541,0.01919371262192726,0.017217814922332764,0.02617761678993702,0.027199499309062958,0.03988815099000931,0.0342630110681057,0.03475779667496681,0.036891840398311615,0.042117469012737274,0.04207585006952286,0.05027870461344719,0.04316981881856918,0.041572436690330505,0.04150870814919472,0.03932633996009827,0.03647218644618988,0.060630541294813156,0.04327068477869034,0.04417034238576889,0.04641779139637947,0.046455018222332,0.04404333233833313,0.047797124832868576]],\"type\":\"heatmap\",\"xaxis\":\"x4\",\"yaxis\":\"y4\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"4\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"y\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"z\":[[1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0026061288081109524,0.9973938465118408,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.005864884238690138,0.007361511699855328,0.9867734909057617,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.008848459459841251,0.007240729406476021,0.017727112397551537,0.966183602809906,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.020618507638573647,0.003754440462216735,0.019391734153032303,0.11906623840332031,0.8371690511703491,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0066808490082621574,0.0033869780600070953,0.012229637242853642,0.04250335693359375,0.3244766294956207,0.6107224822044373,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.03244844451546669,0.02596244588494301,0.016251392662525177,0.01554835494607687,0.04020869731903076,0.16780760884284973,0.7017730474472046,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0014335542218759656,0.0009126539225690067,0.000580708438064903,0.0007340920274145901,0.006572042591869831,0.012076175771653652,0.854302167892456,0.12338866293430328,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.03213861584663391,0.038988158106803894,0.003751081880182028,0.004674091935157776,0.0034876521676778793,0.009955604560673237,0.0433407761156559,0.12222855538129807,0.7414354681968689,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00870131142437458,0.0029649732168763876,0.0010937832994386554,0.003304637735709548,0.006121226120740175,0.008560153655707836,0.06688284128904343,0.05056476965546608,0.5870857238769531,0.2647206485271454,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.002309527713805437,0.0007635169313289225,0.0002710870758164674,0.0005804632091894746,0.0009042726596817374,0.0020078427623957396,0.013455236330628395,0.02906673774123192,0.43099114298820496,0.24282720685005188,0.2768230140209198,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.004125518724322319,0.0024062241427600384,0.0005749395349994302,0.0018440460553392768,0.001201349776238203,0.001958252862095833,0.008308375254273415,0.027823572978377342,0.22348856925964355,0.14601807296276093,0.11631211638450623,0.4659389853477478,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.005022422410547733,0.002328834030777216,0.0009329036111012101,0.0011152877705171704,0.0009851701324805617,0.001929389196448028,0.0047363582998514175,0.02127864398062229,0.08640764653682709,0.08283692598342896,0.08648049831390381,0.5469314455986023,0.1590144783258438,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.001463969238102436,0.00116815569344908,0.00048699299804866314,0.000797840126324445,0.0006079188315197825,0.0011150239733979106,0.003457785816863179,0.01484557893127203,0.03519401699304581,0.0457305908203125,0.060704004019498825,0.5459586977958679,0.10608713328838348,0.1823822408914566,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0009801656706258655,0.0018608961254358292,0.0006044860347174108,0.0003220821381546557,0.00030900296405889094,0.0010287411278113723,0.002217173809185624,0.008780515752732754,0.012451237067580223,0.01962912082672119,0.03751609846949577,0.50011146068573,0.09114190936088562,0.2303653210401535,0.09268175065517426,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0005910475156269968,0.0008998811827041209,0.0004390631802380085,0.0004811058461200446,0.0002994015230797231,0.0006782978889532387,0.001094265840947628,0.0071035572327673435,0.0070635112933814526,0.014547156170010567,0.027870317921042442,0.41924822330474854,0.05358955264091492,0.14693935215473175,0.06344856321811676,0.2557067573070526,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0008354965830221772,0.0016938033513724804,0.0005123897572048008,0.0005108211189508438,0.00029064048430882394,0.0008755185990594327,0.0011005124542862177,0.006686193402856588,0.008150231093168259,0.01380125805735588,0.02420971356332302,0.27175936102867126,0.047963377088308334,0.1335802674293518,0.0547567643225193,0.25115296244621277,0.1821206659078598,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0013313285307958722,0.002460755640640855,0.0012032606173306704,0.0012234015157446265,0.000763185671530664,0.0015700317453593016,0.0014844058314338326,0.007999716326594353,0.005382712930440903,0.011044757440686226,0.02157650515437126,0.1976131945848465,0.03651462122797966,0.0909695103764534,0.03615270555019379,0.15584388375282288,0.11646608263254166,0.3104000389575958,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0017064118292182684,0.004159365780651569,0.0011975917732343078,0.0011952220229431987,0.0005917920498177409,0.0016832994297146797,0.0010849189711734653,0.0064703174866735935,0.0064086755737662315,0.009672955609858036,0.01552652008831501,0.1039402186870575,0.028299739584326744,0.06814859062433243,0.02725798450410366,0.13659615814685822,0.085200235247612,0.3424569368362427,0.15840303897857666,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0015421488787978888,0.003974654711782932,0.0011366766411811113,0.0006621434004046023,0.0003930681268684566,0.0015379233518615365,0.000842747394926846,0.004527437034994364,0.004158500116318464,0.006427673622965813,0.01118419785052538,0.07611183077096939,0.021673185750842094,0.05791556090116501,0.01976560428738594,0.11449610441923141,0.07367505878210068,0.3512383997440338,0.15435147285461426,0.09438561648130417,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0015626433305442333,0.006597007624804974,0.0007047100807540119,0.00038076561759226024,0.00011078926036134362,0.0005852188915014267,0.00031981500796973705,0.0026635813992470503,0.0019968985579907894,0.0034507261589169502,0.005071309860795736,0.05777658522129059,0.010116535238921642,0.034754570573568344,0.011532841250300407,0.0827852338552475,0.04652564600110054,0.3526014983654022,0.12869933247566223,0.06745445728302002,0.18430988490581512,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.001072522602044046,0.004456343129277229,0.0003402356232982129,0.00017428910359740257,5.1097482355544344e-05,0.00034626841079443693,0.0001942657254403457,0.0016184165142476559,0.0020455443300306797,0.002767351921647787,0.0037975292652845383,0.03804219514131546,0.008392463438212872,0.026322828605771065,0.009469078853726387,0.06809107214212418,0.039594076573848724,0.34024766087532043,0.11244535446166992,0.06294246017932892,0.18523362278938293,0.09235529601573944,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0004307481285650283,0.002443162491545081,9.99346375465393e-05,7.454000297002494e-05,1.7830581782618538e-05,0.00013224683061707765,0.00010716898395912722,0.0009450691868551075,0.0015957903815433383,0.0019732534419745207,0.0026602731086313725,0.0312432162463665,0.006466224789619446,0.02064524218440056,0.007520589046180248,0.05686488747596741,0.03358788043260574,0.31584328413009644,0.101608507335186,0.058071017265319824,0.19182182848453522,0.09278637915849686,0.07306092232465744,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0007092072628438473,0.002146193291991949,0.0005552623188123107,0.0003646173281595111,0.0001622253330424428,0.0005475669167935848,0.000330594542901963,0.0023158006370067596,0.0013233862118795514,0.002773464424535632,0.005268420092761517,0.055831488221883774,0.009468951262533665,0.030004378408193588,0.009538154117763042,0.0598585270345211,0.038127925246953964,0.1717245876789093,0.08836235851049423,0.047946471720933914,0.11996399611234665,0.060701146721839905,0.045285291969776154,0.24668997526168823,0.0,0.0,0.0,0.0,0.0,0.0],[0.0009860406862571836,0.0027248351834714413,0.0004730235959868878,0.00045583295286633074,0.0001912781735882163,0.0006718661752529442,0.000495546730235219,0.0025413110852241516,0.0030402722768485546,0.004189502447843552,0.005564877297729254,0.033009689301252365,0.01096038892865181,0.024775205180048943,0.010740297846496105,0.04556809738278389,0.034213677048683167,0.14558210968971252,0.06995844841003418,0.04685544967651367,0.1054777055978775,0.05978124588727951,0.050054121762514114,0.25365957617759705,0.08802958577871323,0.0,0.0,0.0,0.0,0.0],[0.0008808840648271143,0.0018524813931435347,0.0003330951149109751,0.0003217271587345749,0.00016733301163185388,0.0006373290671035647,0.0004953735042363405,0.0021638923790305853,0.0045819999650120735,0.004810007754713297,0.005361002404242754,0.02201722003519535,0.011539609171450138,0.019979670643806458,0.010431142523884773,0.03731906786561012,0.030308237299323082,0.1244695708155632,0.05461258068680763,0.04395934194326401,0.09623738378286362,0.05739517882466316,0.04887773096561432,0.2707407772541046,0.07945971935987473,0.07104761153459549,0.0,0.0,0.0,0.0],[0.000501557718962431,0.0012891915393993258,0.00021567687508650124,0.0002346884284634143,0.00012021353904856369,0.00046830959036014974,0.00035676819970831275,0.001678252243436873,0.0036001228727400303,0.003895294154062867,0.004455972462892532,0.019037658348679543,0.010069507174193859,0.017720825970172882,0.008683698251843452,0.03287193551659584,0.027171986177563667,0.11249406635761261,0.04814910143613815,0.0396440215408802,0.08749037981033325,0.05137275904417038,0.04398687928915024,0.2740726172924042,0.07355812937021255,0.06547220051288605,0.07138817757368088,0.0,0.0,0.0],[0.00024255921016447246,0.0006384248263202608,9.467959898756817e-05,0.00011808748240582645,6.653377204202116e-05,0.0002710426924750209,0.0002504300500731915,0.001141282613389194,0.003232843242585659,0.0032232520170509815,0.0036533039528876543,0.015472116880118847,0.008934605866670609,0.014665220864117146,0.0074629588052630424,0.027277661487460136,0.023803940042853355,0.09672486782073975,0.042117640376091,0.03623512014746666,0.0832594707608223,0.04882894828915596,0.042349740862846375,0.2807020843029022,0.0685214251279831,0.06089764088392258,0.06623964756727219,0.06357438862323761,0.0,0.0],[7.910637941677123e-05,0.00022679449466522783,3.427134288358502e-05,5.85393063374795e-05,3.872032175422646e-05,0.00015558685117866844,0.00017929905152413994,0.0007673536892980337,0.0028901342302560806,0.002714680042117834,0.0032084695994853973,0.012976627796888351,0.00850588921457529,0.012801732867956161,0.006575646810233593,0.023128222674131393,0.021761449053883553,0.08038504421710968,0.036522671580314636,0.03412516042590141,0.07933436334133148,0.0468674935400486,0.04164588823914528,0.2986270785331726,0.0653124451637268,0.05842975527048111,0.06359913945198059,0.060889896005392075,0.038158562034368515,0.0],[0.01259834598749876,0.016848577186465263,0.014731633476912975,0.01414389070123434,0.012272007763385773,0.016150766983628273,0.013313832692801952,0.021054474636912346,0.01706378161907196,0.020764827728271484,0.02469256892800331,0.040053997188806534,0.028286386281251907,0.037940334528684616,0.027470044791698456,0.04237443581223488,0.03760216385126114,0.05330232158303261,0.044092871248722076,0.039366915822029114,0.04662449285387993,0.04125743359327316,0.03840947896242142,0.05700412765145302,0.04679075628519058,0.04824773967266083,0.049238208681344986,0.04892321303486824,0.046032100915908813,0.04334826394915581]],\"type\":\"heatmap\",\"xaxis\":\"x5\",\"yaxis\":\"y5\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"5\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"y\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"z\":[[1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.002538475440815091,0.9974615573883057,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.003965683747082949,0.008960130624473095,0.9870742559432983,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.004980898927897215,0.002998286858201027,0.012505581602454185,0.9795152544975281,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.002145345089957118,0.003203283529728651,0.005766663700342178,0.19715015590190887,0.7917346358299255,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0020460980013012886,0.0033145190682262182,0.006579034496098757,0.13779114186763763,0.08632318675518036,0.7639460563659668,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0033950128126889467,0.0025538871996104717,0.007425324991345406,0.11447754502296448,0.01680924743413925,0.19007915258407593,0.6652597784996033,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0018992810510098934,0.0028984397649765015,0.0015079901786521077,0.007401128299534321,0.01159348152577877,0.01402233261615038,0.6987301707267761,0.2619471848011017,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.007145460695028305,0.027773112058639526,0.003503672545775771,0.006072963122278452,0.01016141939908266,0.02059677056968212,0.16332882642745972,0.17111164331436157,0.5903061628341675,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0013562970561906695,0.0013451386475935578,0.0006048637442290783,0.002769629703834653,0.0023359940387308598,0.004174781497567892,0.037601031363010406,0.036560624837875366,0.728776752948761,0.18447479605674744,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0003449991927482188,0.0002618928556330502,0.0001223477884195745,0.0006707012071274221,0.000365537591278553,0.0011895784409716725,0.004144027829170227,0.012723343446850777,0.48811519145965576,0.1003493145108223,0.39171302318573,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0006612331490032375,0.0005521744024008512,0.00041548494482412934,0.0022189703304320574,0.0016388559015467763,0.0035593886859714985,0.007817291654646397,0.022962279617786407,0.18689288198947906,0.07525307685136795,0.563580334186554,0.1344480663537979,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0007714329985901713,0.0003624990349635482,0.0005027748993597925,0.002456512302160263,0.001378190005198121,0.0034944587387144566,0.004993980750441551,0.016215195879340172,0.07462400197982788,0.04262698441743851,0.39355748891830444,0.07176905125379562,0.38724732398986816,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[8.711779810255393e-05,4.567321957438253e-05,6.215894973138347e-05,0.0004018071049358696,0.00014377987827174366,0.000514467537868768,0.0009068356011994183,0.003956461325287819,0.046585265547037125,0.01723048835992813,0.24205312132835388,0.03497802093625069,0.502543032169342,0.1504918485879898,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[3.420062785153277e-05,5.6199616665253416e-05,2.808082899719011e-05,6.011596997268498e-05,2.9220640499261208e-05,0.00013472230057232082,0.0005926331505179405,0.00203987886197865,0.016099803149700165,0.005811008624732494,0.1389075219631195,0.021735377609729767,0.5760796070098877,0.1508452147245407,0.08754647523164749,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[2.3942098778206855e-05,4.602697663358413e-05,2.909300928877201e-05,8.032484765863046e-05,4.265524330548942e-05,0.00016300643619615585,0.0003580675693228841,0.0017170361243188381,0.015085140243172646,0.006212486419826746,0.10562340915203094,0.020404066890478134,0.4012313187122345,0.10694416612386703,0.06495660543441772,0.2770826518535614,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[7.463103247573599e-05,0.00010740834113676101,7.47289668652229e-05,0.00023274861450772732,9.960085299098864e-05,0.0004404060891829431,0.0006153919966891408,0.002979688113555312,0.012983459047973156,0.007086843717843294,0.1202533170580864,0.02072902023792267,0.2207701951265335,0.09560937434434891,0.05494534969329834,0.25230228900909424,0.2106955647468567,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0003774471115320921,0.0007148810545913875,0.0004026330716442317,0.0006181775243021548,0.00032499723602086306,0.0011092814384028316,0.001281616510823369,0.005131173878908157,0.010902906768023968,0.007678885944187641,0.08153301477432251,0.020673571154475212,0.14099551737308502,0.07440470904111862,0.04299383610486984,0.18219317495822906,0.16450338065624237,0.26416081190109253,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0009163600625470281,0.0008565625757910311,0.0006432670634239912,0.0011426412966102362,0.0002796052140183747,0.00175049330573529,0.0005991115467622876,0.0053470926359295845,0.01171239372342825,0.007611941080540419,0.06306883692741394,0.014898702502250671,0.0667174905538559,0.048366595059633255,0.03297119215130806,0.14829739928245544,0.14328080415725708,0.3614020347595215,0.09013756364583969,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0009039368014782667,0.0015459388960152864,0.0006747890147380531,0.0006277859793044627,0.000195385015103966,0.001322696334682405,0.0005007127765566111,0.004473642911761999,0.006462819874286652,0.004909639712423086,0.039197877049446106,0.011484198272228241,0.048446156084537506,0.03857007622718811,0.02437814697623253,0.12427099794149399,0.12570832669734955,0.38926106691360474,0.08040346205234528,0.09666239470243454,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0011276635341346264,0.0019989963620901108,0.000628038658760488,0.0005486482405103743,0.00012969682575203478,0.0011099266121163964,0.00030915328534319997,0.0036540604196488857,0.00456400029361248,0.0037996864411979914,0.027306143194437027,0.008215362206101418,0.02921176329255104,0.026872212067246437,0.01732197217643261,0.09911151975393295,0.10163770616054535,0.4334087073802948,0.06652726978063583,0.08079755306243896,0.09172000735998154,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0008935311925597489,0.0015621887287124991,0.0004176353686489165,0.00034264029818587005,6.124349602032453e-05,0.0007200803956948221,0.00017503375420346856,0.002405041828751564,0.0035665654577314854,0.002696486422792077,0.015772191807627678,0.005787851754575968,0.017603866755962372,0.0182841494679451,0.012590275146067142,0.06938405334949493,0.0760168731212616,0.464246928691864,0.05557573586702347,0.07222257554531097,0.07584749162197113,0.10382745414972305,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0003855630347970873,0.0008671979303471744,0.0001507741690147668,0.00014384277164936066,2.3553815481136553e-05,0.0003164504887536168,0.00010292692604707554,0.0013943068915978074,0.00244518113322556,0.0017087990418076515,0.012020662426948547,0.004007980693131685,0.015479007735848427,0.014568117447197437,0.009867803193628788,0.05950123444199562,0.06513932347297668,0.4316588342189789,0.050085049122571945,0.06601972132921219,0.071732297539711,0.10156983882188797,0.09081155061721802,0.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.00039726856630295515,0.0009539396851323545,0.0003607683756854385,0.00031527935061603785,0.0001294286485062912,0.0006937168072909117,0.00042032572673633695,0.0025232979096472263,0.0028484747745096684,0.0024960124865174294,0.02312745340168476,0.006827834993600845,0.02979569137096405,0.023387620225548744,0.01294422335922718,0.06948103755712509,0.0655689388513565,0.16981437802314758,0.04465894773602486,0.049587421119213104,0.05890614166855812,0.07801023125648499,0.06703002750873566,0.2897215187549591,0.0,0.0,0.0,0.0,0.0,0.0],[0.0006908657378517091,0.0018892604857683182,0.0005055450601503253,0.00040391762740910053,0.000166359925060533,0.0009534310665912926,0.00046727192238904536,0.002686952007934451,0.003874679794535041,0.003109689336270094,0.011895433999598026,0.006502778269350529,0.020231930539011955,0.01725638657808304,0.012271122075617313,0.04143603891134262,0.04851927608251572,0.16384457051753998,0.042451225221157074,0.048593685030937195,0.05275176092982292,0.06485151499509811,0.058993905782699585,0.32220524549484253,0.07344712316989899,0.0,0.0,0.0,0.0,0.0],[0.0007316161645576358,0.0015019649872556329,0.0005439954111352563,0.00045472264173440635,0.0001314826513407752,0.0009650640422478318,0.000331965449731797,0.0022592442110180855,0.004676601849496365,0.0032015317119657993,0.008705138228833675,0.005373790394514799,0.015046722255647182,0.013471339829266071,0.010938175022602081,0.030824407935142517,0.03934713080525398,0.14903457462787628,0.03577554225921631,0.044712767004966736,0.04751354083418846,0.059531331062316895,0.0546867772936821,0.3351009786128998,0.06814000755548477,0.06699962168931961,0.0,0.0,0.0,0.0],[0.00035467627458274364,0.0009824964217841625,0.0003087242948822677,0.0002488766622263938,8.19729539216496e-05,0.0006241543451324105,0.00023676901764702052,0.001590517582371831,0.0035804982762783766,0.002339176367968321,0.0070311627350747585,0.004386940971016884,0.01418133545666933,0.011903098784387112,0.009376524947583675,0.02679242193698883,0.03506864607334137,0.12977752089500427,0.03282682225108147,0.041207123547792435,0.04454078897833824,0.05553046241402626,0.051128268241882324,0.3348022997379303,0.0623253658413887,0.061724089086055756,0.06704920530319214,0.0,0.0,0.0],[0.0001540693046990782,0.0005321191274560988,0.00013861391926184297,0.00011774538143072277,4.224745134706609e-05,0.00034066810621879995,0.00015453563537448645,0.0010151491733267903,0.0029848008416593075,0.0017071818001568317,0.005328150931745768,0.0034306261222809553,0.013275125063955784,0.009952755644917488,0.00802541896700859,0.022040216252207756,0.030034853145480156,0.10937328636646271,0.02964654006063938,0.03841273486614227,0.04279964417219162,0.05320192873477936,0.04992426186800003,0.3386494517326355,0.05794980376958847,0.05771647021174431,0.06240818649530411,0.060643382370471954,0.0,0.0],[2.9550732506322674e-05,0.00013354248949326575,3.345615914440714e-05,3.556780211511068e-05,1.3526343536796048e-05,0.00012003046867903322,6.854107778053731e-05,0.00045413474435918033,0.0022029271349310875,0.0010111622978001833,0.003914081957191229,0.002322360873222351,0.013165973126888275,0.0079293018206954,0.006375724915415049,0.017395950853824615,0.024465177208185196,0.08183010667562485,0.02569703944027424,0.03555108979344368,0.04215623438358307,0.05373501032590866,0.05115547776222229,0.3583788275718689,0.056220393627882004,0.05752384290099144,0.06135382503271103,0.05829838290810585,0.03842874616384506,0.0],[0.008988557383418083,0.012396248057484627,0.013517911545932293,0.012400857172906399,0.010693696327507496,0.01465698517858982,0.011938448064029217,0.018146982416510582,0.022809505462646484,0.0205540768802166,0.03191831707954407,0.025977417826652527,0.04085808992385864,0.036120954900979996,0.031086089089512825,0.04020483419299126,0.0409473218023777,0.04912872239947319,0.04093359410762787,0.04200863838195801,0.04319635406136513,0.04682311415672302,0.04518996551632881,0.061038658022880554,0.04692346975207329,0.04874692112207413,0.04867735877633095,0.04765584319829941,0.04355468600988388,0.04290640354156494]],\"type\":\"heatmap\",\"xaxis\":\"x6\",\"yaxis\":\"y6\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.15],\"title\":{\"text\":\"Key\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"title\":{\"text\":\"Query\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.16999999999999998,0.31999999999999995],\"matches\":\"x\",\"title\":{\"text\":\"Key\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.33999999999999997,0.49],\"matches\":\"x\",\"title\":{\"text\":\"Key\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.51,0.66],\"matches\":\"x\",\"title\":{\"text\":\"Key\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.6799999999999999,0.83],\"matches\":\"x\",\"title\":{\"text\":\"Key\"}},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis6\":{\"anchor\":\"y6\",\"domain\":[0.85,1.0],\"matches\":\"x\",\"title\":{\"text\":\"Key\"}},\"yaxis6\":{\"anchor\":\"x6\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"annotations\":[{\"font\":{},\"showarrow\":false,\"text\":\"Head 0\",\"x\":0.075,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Head 1\",\"x\":0.24499999999999997,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Head 2\",\"x\":0.415,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Head 3\",\"x\":0.585,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Head 4\",\"x\":0.7549999999999999,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Head 5\",\"x\":0.925,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Attention Patterns in Layer 0\"},\"width\":5000},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a8227724-255c-4bca-8e09-98fcd9e7ffc9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.save(hooked_model.state_dict(), \"arithseq.pth\")"
      ],
      "metadata": {
        "id": "hYZ-r9TP4a5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('loss_history_arithseq.txt', 'w') as f:\n",
        "    f.write(str(loss_history))\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "_GQDqYyC4jAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot.imshow(\n",
        "    cache['pattern', 1].squeeze(dim=0),\n",
        "    x=np.arange(4),\n",
        "    y=np.arange(4),\n",
        "    facet_col=0, # This argument tells plotly which dimension to split into separate plots\n",
        "    facet_labels=[f\"Head {i}\" for i in range(12)], # Subtitles of separate plots\n",
        "    title=\"Attention Patterns in Layer 0\",\n",
        "    xaxis = \"Key\",\n",
        "    yaxis = \"Query\",\n",
        "    width=5000\n",
        ")"
      ],
      "metadata": {
        "id": "lHtu10oN2Xef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "outputId": "61f0e8f9-a560-43d5-e7f7-dc2a062bc4fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"f07b3a19-81d8-42a4-ab4f-16dc4ce4f64a\" class=\"plotly-graph-div\" style=\"height:525px; width:5000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f07b3a19-81d8-42a4-ab4f-16dc4ce4f64a\")) {                    Plotly.newPlot(                        \"f07b3a19-81d8-42a4-ab4f-16dc4ce4f64a\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[0,1,2,3],\"y\":[0,1,2,3],\"z\":[[1.0,0.0,0.0,0.0],[0.4494226276874542,0.5505774021148682,0.0,0.0],[0.24818050861358643,0.29949620366096497,0.4523232579231262,0.0],[0.17950958013534546,0.20429489016532898,0.271293967962265,0.34490156173706055]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"1\",\"x\":[0,1,2,3],\"y\":[0,1,2,3],\"z\":[[1.0,0.0,0.0,0.0],[0.4414162337779999,0.5585837960243225,0.0,0.0],[0.1883631944656372,0.2488277703523636,0.5628089904785156,0.0],[0.004085797816514969,0.005916126538068056,0.016427338123321533,0.9735707640647888]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"2\",\"x\":[0,1,2,3],\"y\":[0,1,2,3],\"z\":[[1.0,0.0,0.0,0.0],[0.501636266708374,0.498363733291626,0.0,0.0],[0.31411945819854736,0.3271150588989258,0.35876548290252686,0.0],[0.13236531615257263,0.1560528576374054,0.22784602642059326,0.4837357699871063]],\"type\":\"heatmap\",\"xaxis\":\"x3\",\"yaxis\":\"y3\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"3\",\"x\":[0,1,2,3],\"y\":[0,1,2,3],\"z\":[[1.0,0.0,0.0,0.0],[0.9424832463264465,0.05751680210232735,0.0,0.0],[0.9430426955223083,0.056883327662944794,7.397453009616584e-05,0.0],[0.9292821884155273,0.07055364549160004,0.00016417130245827138,1.8743931753939513e-11]],\"type\":\"heatmap\",\"xaxis\":\"x4\",\"yaxis\":\"y4\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"4\",\"x\":[0,1,2,3],\"y\":[0,1,2,3],\"z\":[[1.0,0.0,0.0,0.0],[0.49661868810653687,0.5033813118934631,0.0,0.0],[0.3253791928291321,0.3314749300479889,0.3431459069252014,0.0],[0.2377965748310089,0.24494469165802002,0.26144731044769287,0.2558113932609558]],\"type\":\"heatmap\",\"xaxis\":\"x5\",\"yaxis\":\"y5\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"5\",\"x\":[0,1,2,3],\"y\":[0,1,2,3],\"z\":[[1.0,0.0,0.0,0.0],[0.45721858739852905,0.5427813529968262,0.0,0.0],[0.2142299860715866,0.2661080062389374,0.5196619629859924,0.0],[0.0060958643443882465,0.00840017106384039,0.020724426954984665,0.9647796154022217]],\"type\":\"heatmap\",\"xaxis\":\"x6\",\"yaxis\":\"y6\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"6\",\"x\":[0,1,2,3],\"y\":[0,1,2,3],\"z\":[[1.0,0.0,0.0,0.0],[0.5175531506538391,0.4824468195438385,0.0,0.0],[0.3526591360569,0.3384850323200226,0.3088558316230774,0.0],[0.21224157512187958,0.2211916744709015,0.24501259624958038,0.3215540945529938]],\"type\":\"heatmap\",\"xaxis\":\"x7\",\"yaxis\":\"y7\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"7\",\"x\":[0,1,2,3],\"y\":[0,1,2,3],\"z\":[[1.0,0.0,0.0,0.0],[0.4755610525608063,0.5244389176368713,0.0,0.0],[0.2381582409143448,0.27601927518844604,0.4858224093914032,0.0],[0.003040306968614459,0.004003480542451143,0.00946157705038786,0.9834946990013123]],\"type\":\"heatmap\",\"xaxis\":\"x8\",\"yaxis\":\"y8\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"8\",\"x\":[0,1,2,3],\"y\":[0,1,2,3],\"z\":[[1.0,0.0,0.0,0.0],[0.5397153496742249,0.46028462052345276,0.0,0.0],[0.42650848627090454,0.36181360483169556,0.2116779237985611,0.0],[0.4178518056869507,0.3547699749469757,0.2103077471256256,0.017070412635803223]],\"type\":\"heatmap\",\"xaxis\":\"x9\",\"yaxis\":\"y9\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"9\",\"x\":[0,1,2,3],\"y\":[0,1,2,3],\"z\":[[1.0,0.0,0.0,0.0],[0.5012896656990051,0.49871039390563965,0.0,0.0],[0.3344927728176117,0.3335481882095337,0.3319590985774994,0.0],[0.25205254554748535,0.25321605801582336,0.25522613525390625,0.23950527608394623]],\"type\":\"heatmap\",\"xaxis\":\"x10\",\"yaxis\":\"y10\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"10\",\"x\":[0,1,2,3],\"y\":[0,1,2,3],\"z\":[[1.0,0.0,0.0,0.0],[0.5329983234405518,0.46700167655944824,0.0,0.0],[0.3619857132434845,0.3434850573539734,0.2945292294025421,0.0],[0.08987347781658173,0.1069217324256897,0.1665320098400116,0.6366727948188782]],\"type\":\"heatmap\",\"xaxis\":\"x11\",\"yaxis\":\"y11\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"},{\"coloraxis\":\"coloraxis\",\"name\":\"11\",\"x\":[0,1,2,3],\"y\":[0,1,2,3],\"z\":[[1.0,0.0,0.0,0.0],[0.5489364266395569,0.4510635435581207,0.0,0.0],[0.3797932267189026,0.34663307666778564,0.2735736668109894,0.0],[0.06925873458385468,0.08504678308963776,0.14469553530216217,0.7009989619255066]],\"type\":\"heatmap\",\"xaxis\":\"x12\",\"yaxis\":\"y12\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.065],\"title\":{\"text\":\"Key\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"title\":{\"text\":\"Query\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.085,0.15000000000000002],\"matches\":\"x\",\"title\":{\"text\":\"Key\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.17,0.23500000000000001],\"matches\":\"x\",\"title\":{\"text\":\"Key\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.255,0.32],\"matches\":\"x\",\"title\":{\"text\":\"Key\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.34,0.405],\"matches\":\"x\",\"title\":{\"text\":\"Key\"}},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis6\":{\"anchor\":\"y6\",\"domain\":[0.42500000000000004,0.49000000000000005],\"matches\":\"x\",\"title\":{\"text\":\"Key\"}},\"yaxis6\":{\"anchor\":\"x6\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis7\":{\"anchor\":\"y7\",\"domain\":[0.51,0.575],\"matches\":\"x\",\"title\":{\"text\":\"Key\"}},\"yaxis7\":{\"anchor\":\"x7\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis8\":{\"anchor\":\"y8\",\"domain\":[0.595,0.6599999999999999],\"matches\":\"x\",\"title\":{\"text\":\"Key\"}},\"yaxis8\":{\"anchor\":\"x8\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis9\":{\"anchor\":\"y9\",\"domain\":[0.68,0.7450000000000001],\"matches\":\"x\",\"title\":{\"text\":\"Key\"}},\"yaxis9\":{\"anchor\":\"x9\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis10\":{\"anchor\":\"y10\",\"domain\":[0.7649999999999999,0.8299999999999998],\"matches\":\"x\",\"title\":{\"text\":\"Key\"}},\"yaxis10\":{\"anchor\":\"x10\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis11\":{\"anchor\":\"y11\",\"domain\":[0.8499999999999999,0.9149999999999998],\"matches\":\"x\",\"title\":{\"text\":\"Key\"}},\"yaxis11\":{\"anchor\":\"x11\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis12\":{\"anchor\":\"y12\",\"domain\":[0.9349999999999998,0.9999999999999998],\"matches\":\"x\",\"title\":{\"text\":\"Key\"}},\"yaxis12\":{\"anchor\":\"x12\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"annotations\":[{\"font\":{},\"showarrow\":false,\"text\":\"Head 0\",\"x\":0.0325,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Head 1\",\"x\":0.11750000000000002,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Head 2\",\"x\":0.2025,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Head 3\",\"x\":0.2875,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Head 4\",\"x\":0.37250000000000005,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Head 5\",\"x\":0.4575,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Head 6\",\"x\":0.5425,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Head 7\",\"x\":0.6275,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Head 8\",\"x\":0.7125000000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Head 9\",\"x\":0.7974999999999999,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Head 10\",\"x\":0.8824999999999998,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Head 11\",\"x\":0.9674999999999998,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Attention Patterns in Layer 0\"},\"width\":5000},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f07b3a19-81d8-42a4-ab4f-16dc4ce4f64a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yhWAAIwlDDvx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}